# Produce dan Consume menggunakan Schema Registry

## Produce dan Consume menggunakan Schema Registry di Java

Pertama, pastikan status schema registry pada vm confluent sudah running dan port 8081 bisa di-telnet dari client:

```
sudo systemctl status confluent-schema-registry
```

![image](https://github.com/user-attachments/assets/0ba14b8e-575d-495e-bb43-097ed45a34e7)

Pada file `pom.xml`, tambahkan library berikut di bagian Dependency:

```
<!-- Confluent Kafka Avro Serializer -->
<dependency>
        <groupId>io.confluent</groupId>
        <artifactId>kafka-avro-serializer</artifactId>
        <version>7.0.0</version>
</dependency>

<!-- Avro -->
<dependency>
    <groupId>org.apache.avro</groupId>
    <artifactId>avro</artifactId>
    <version>1.10.2</version>
</dependency>
```

Dan tambahkan Confluent Maven Repositories:

```
<repositories>
        <repository>
            <id>confluent</id>
            <url>https://packages.confluent.io/maven/</url>
        </repository>
</repositories>
```

### Producer

Ubah kode di file `Producer.java` hingga menjadi seperti berikut:

```
package com.example;

import org.apache.kafka.clients.producer.*;
import org.apache.kafka.common.serialization.StringSerializer;

import io.confluent.kafka.serializers.KafkaAvroSerializer;
import org.apache.avro.Schema;
import org.apache.avro.generic.GenericData;
import org.apache.avro.generic.GenericRecord;

import java.util.Properties;

public class Producer {
    public static void main(String[] args) {
        String bootstrapServers = "10.100.13.149:9092";
        String schemaRegistryUrl = "http://10.100.13.149:8081";
        String topic = "test_topic_schema";

        // Avro schema definition
        String userSchema = 
        "{"
            + "\"type\": \"record\","
            + "\"name\": \"User\","
            + "\"fields\": ["
                + "{ \"name\": \"name\", \"type\": \"string\" },"
                + "{ \"name\": \"age\", \"type\": \"int\" }"
            + "]"
        + "}";

        Schema.Parser parser = new Schema.Parser();
        Schema schema = parser.parse(userSchema);

        // Create a GenericRecord with the schema
        GenericRecord avroRecord = new GenericData.Record(schema);
        avroRecord.put("name", "Ivy");
        avroRecord.put("age", 21);

        // Producer properties
        Properties properties = new Properties();
        properties.setProperty(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);
        properties.setProperty(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        properties.setProperty(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, KafkaAvroSerializer.class.getName());
        properties.setProperty("schema.registry.url", schemaRegistryUrl);  // Setting Schema Registry URL

        // Create the producer
        KafkaProducer<String, GenericRecord> producer = new KafkaProducer<>(properties);

        // Send data
        ProducerRecord<String, GenericRecord> record = new ProducerRecord<>(topic, "key", avroRecord);
        producer.send(record, (metadata, exception) -> {
            if (exception == null) {
                System.out.println("Sent message with offset: " + metadata.offset());
            } else {
                exception.printStackTrace();
            }
        });

        // Flush and close producer
        producer.flush();
        producer.close();
    }
}
```

Berdasarkan kode di atas, berikut adalah library-library tambahan yang diimport untuk menggunakan schema registry.

```
import io.confluent.kafka.serializers.KafkaAvroSerializer;
import org.apache.avro.Schema;
import org.apache.avro.generic.GenericData;
import org.apache.avro.generic.GenericRecord;
```

Berikut adalah konfigurasi yang ditambahkan:

```
String schemaRegistryUrl = "http://10.100.13.149:8081";

// Avro schema definition
String userSchema = 
"{"
    + "\"type\": \"record\","
    + "\"name\": \"User\","
    + "\"fields\": ["
        + "{ \"name\": \"name\", \"type\": \"string\", \"default\": \"Unknown\"},"
        + "{ \"name\": \"age\", \"type\": \"int\", \"default\": 0 }"
    + "]"
+ "}";
Schema.Parser parser = new Schema.Parser();
Schema schema = parser.parse(userSchema);

// Create a GenericRecord with the schema
GenericRecord avroRecord = new GenericData.Record(schema);
avroRecord.put("name", "Ivy");
avroRecord.put("age", 21);
```

Dengan kode di atas, message ditetapkan untuk mengikuti format userSchema yang menyertakan nama dan umur. Lalu, pastikan value yang dikirim diambil dari avroRecord, bukan string yang sebelumnya.

```
properties.setProperty(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, KafkaAvroSerializer.class.getName());
properties.setProperty("schema.registry.url", schemaRegistryUrl);  // Setting Schema Registry URL

// Create the producer
KafkaProducer<String, GenericRecord> producer = new KafkaProducer<>(properties);

// Send data
ProducerRecord<String, GenericRecord> record = new ProducerRecord<>(topic, "key", avroRecord);
```

### Consumer

Ubah kode di file `Consumer.java` menjadi berikut:

```
package com.example;

import org.apache.kafka.clients.consumer.*;
import org.apache.kafka.common.serialization.StringDeserializer;
import io.confluent.kafka.serializers.KafkaAvroDeserializer;
import org.apache.avro.generic.GenericRecord;

import java.time.Duration;
import java.util.Collections;
import java.util.Properties;

public class Consumer {
    public static void main(String[] args) {
        String bootstrapServers = "10.100.13.149:9092";
        String schemaRegistryUrl = "http://10.100.13.149:8081";
        String groupId = "java-group";
        String topic = "test_topic_schema";

        // Consumer properties
        Properties properties = new Properties();
        properties.setProperty(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);
        properties.setProperty(ConsumerConfig.GROUP_ID_CONFIG, groupId);
        properties.setProperty(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        properties.setProperty(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, KafkaAvroDeserializer.class.getName()); // Avro Deserializer
        properties.setProperty(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest");
        properties.setProperty("schema.registry.url", schemaRegistryUrl); // Schema Registry URL
        properties.setProperty("specific.avro.reader", "false"); // Use GenericRecord

        // Create the consumer
        KafkaConsumer<String, GenericRecord> consumer = new KafkaConsumer<>(properties);

        // Subscribe to the topic
        consumer.subscribe(Collections.singleton(topic));

        // Poll for new data
        while (true) {
            ConsumerRecords<String, GenericRecord> records = consumer.poll(Duration.ofMillis(100));
            for (ConsumerRecord<String, GenericRecord> record : records) {
                String name = record.value().get("name").toString();
                int age = (int) record.value().get("age");

                System.out.println("Received message: Name = " + name + ", Age = " + age + 
                                   ", Offset: " + record.offset());
            }
        }
    }
}

```

Berdasarkan kode di atas, berikut adalah library-library tambahan yang diimport untuk menggunakan schema registry.

```
import io.confluent.kafka.serializers.KafkaAvroDeserializer;
import org.apache.avro.generic.GenericRecord;
```

Berikut adalah konfigurasi yang ditambahkan:

```
String schemaRegistryUrl = "http://10.100.13.149:8081";

properties.setProperty(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, KafkaAvroDeserializer.class.getName()); // Avro Deserializer
properties.setProperty("schema.registry.url", schemaRegistryUrl); // Schema Registry URL
properties.setProperty("specific.avro.reader", "false"); // Use GenericRecord
```

Dengan kode di atas, message ditetapkan di-deserialize menggunakan schema registry. Lalu, pastikan polling message berupa GenericRecord yang menyertakan nama dan umur.

```
// Create the consumer
KafkaConsumer<String, GenericRecord> consumer = new KafkaConsumer<>(properties);

// Subscribe to the topic
consumer.subscribe(Collections.singleton(topic));

// Poll for new data
while (true) {
    ConsumerRecords<String, GenericRecord> records = consumer.poll(Duration.ofMillis(100));
    for (ConsumerRecord<String, GenericRecord> record : records) {
        String name = record.value().get("name").toString();
        int age = (int) record.value().get("age");

        System.out.println("Received message: Name = " + name + ", Age = " + age + 
                           ", Offset: " + record.offset());
    }
}
```

Jalankan `mvn clean package` dan jalankan Producer dan consumer:

```
java -cp target/kafka-producer-consumer-1.0-SNAPSHOT-shaded.jar com.example.Producer
```

![image](https://github.com/user-attachments/assets/f274c236-49d0-4cc8-a356-e3841fbca4a9)

```
java -cp target/kafka-producer-consumer-1.0-SNAPSHOT-shaded.jar com.example.Consumer
```

![image](https://github.com/user-attachments/assets/06bff178-2cf3-482f-b41e-cfcf2cf9f915)

## Notes

1. Apa fungsi `->` (lambda), apa keuntungan dan kekurangannya?

```
producer.send(record, (metadata, exception) -> {
    if (exception == null) {
        System.out.println("Sent message with offset: " + metadata.offset());
    } else {
        exception.printStackTrace();
    }
});
```

Lambda di Java adalah ekspresi yang memungkinkan untuk mendefinisikan fungsi anonim (fungsi tanpa nama) yang dapat digunakan sebagai parameter atau sebagai return value dari suatu method. Dalam kode di atas, ada dua kondisi yang ditangani: jika tidak ada exception, ia mencetak offset. Jika ada exception, ia menampilkan stack trace dari error tersebut.

Contoh penggunaan lambda untuk menggantikan class anonim sebelum lambda:

```
new Thread(new Runnable() {
    @Override
    public void run() {
        System.out.println("Hello World");
    }
}).start();
```

Setelah menggunakan lambda:

```
new Thread(() -> System.out.println("Hello World")).start();
```

Keuntungan Lambda:
- Kode lebih singkat dan bersih
- Lebih mudah dibaca. Dengan lambda, fokus hanya pada logika, tanpa harus mendefinisikan implementasi class tambahan.
- Efisiensi kode dengan mengurangi kompleksitas dan ukuran kode yang diperlukan untuk tugas sederhana.
  
Kerugian Lambda:
- Debugging lebih sulit karena lambda tidak memiliki nama (anonymous), saat error, akan lebih sulit untuk melacak dan mengidentifikasi dalam call stack.
- Jika logika di dalam lambda terlalu kompleks, kode malah menjadi lebih sulit dimengerti daripada jika menggunakan class anonim atau implementasi method biasa.
