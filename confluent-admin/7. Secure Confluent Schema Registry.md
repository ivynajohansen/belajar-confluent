# Secure Confluent Schema Registry

## Connect ke Schema Registry dengan HTTPS

Ubah `docker-compose.yaml` menjadi seperti berikut dengan menambahkan konfigurasi SASL-INT, SSL-INT, menambahkan schema registry dan restproxy:

```
version: "3.5"
services:
  zk-1:
    image: confluentinc/cp-zookeeper:7.1.1-1-ubi8
    restart: always
    container_name: zk-1
    hostname: zk-1
    ports:
      - "12181:12181"
    volumes:
      - data-zk-log-1:/var/lib/zookeeper/log
      - data-zk-data-1:/var/lib/zookeeper/data
      - /root/belajar-confluent/tls/zk-creds:/etc/kafka/secrets
    networks:
      - tls_confluent
    environment:
      - ZOOKEEPER_SERVER_ID=1
      - ZOOKEEPER_CLIENT_PORT=12181
      - ZOOKEEPER_TICK_TIME=2000
      - ZOOKEEPER_INIT_LIMIT=5
      - ZOOKEEPER_SYNC_LIMIT=2
      - ZOOKEEPER_SERVERS=zk-1:2888:3888;zk-2:2888:3888;zk-3:2888:3888
      - ZOOKEEPER_AUTH_PROVIDER_SASL=org.apache.zookeeper.server.auth.SASLAuthenticationProvider
      - KAFKA_OPTS=-Djava.security.auth.login.config=/etc/kafka/secrets/zk-jaas.conf
  
  zk-2:
    image: confluentinc/cp-zookeeper:7.1.1-1-ubi8
    restart: always
    container_name: zk-2
    hostname: zk-2
    ports:
      - "22181:22181"
    volumes:
      - data-zk-log-2:/var/lib/zookeeper/log
      - data-zk-data-2:/var/lib/zookeeper/data
      - /root/belajar-confluent/tls/zk-creds:/etc/kafka/secrets
    networks:
      - tls_confluent
    environment:
      - ZOOKEEPER_SERVER_ID=2
      - ZOOKEEPER_CLIENT_PORT=22181
      - ZOOKEEPER_TICK_TIME=2000
      - ZOOKEEPER_INIT_LIMIT=5
      - ZOOKEEPER_SYNC_LIMIT=2
      - ZOOKEEPER_SERVERS=zk-1:2888:3888;zk-2:2888:3888;zk-3:2888:3888
      - ZOOKEEPER_AUTH_PROVIDER_SASL=org.apache.zookeeper.server.auth.SASLAuthenticationProvider
      - KAFKA_OPTS=-Djava.security.auth.login.config=/etc/kafka/secrets/zk-jaas.conf
  
  zk-3:
    image: confluentinc/cp-zookeeper:7.1.1-1-ubi8
    restart: always
    container_name: zk-3
    hostname: zk-3
    ports:
      - "32181:32181"
    volumes:
      - data-zk-log-3:/var/lib/zookeeper/log
      - data-zk-data-3:/var/lib/zookeeper/data
      - /root/belajar-confluent/tls/zk-creds:/etc/kafka/secrets
    networks:
      - tls_confluent
    environment:
      - ZOOKEEPER_SERVER_ID=3
      - ZOOKEEPER_CLIENT_PORT=32181
      - ZOOKEEPER_TICK_TIME=2000
      - ZOOKEEPER_INIT_LIMIT=5
      - ZOOKEEPER_SYNC_LIMIT=2
      - ZOOKEEPER_SERVERS=zk-1:2888:3888;zk-2:2888:3888;zk-3:2888:3888
      - ZOOKEEPER_AUTH_PROVIDER_SASL=org.apache.zookeeper.server.auth.SASLAuthenticationProvider
      - KAFKA_OPTS=-Djava.security.auth.login.config=/etc/kafka/secrets/zk-jaas.conf

  kafka-1:
    image: confluentinc/cp-server:7.1.1-1-ubi8
    restart: always
    container_name: kafka-1
    hostname: kafka-1
    ports:
      - "19092:19092"
      - "19093:19093"      
    networks:
      - tls_confluent
    volumes:
      - data-kafka-1:/var/lib/kafka/data
      - /root/belajar-confluent/tls/kafka-1-creds:/etc/kafka/secrets
    environment:
      KAFKA_BROKER_ID: 101
      KAFKA_ZOOKEEPER_CONNECT: zk-1:12181,zk-2:22181,zk-3:32181
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_DELETE_TOPIC_ENABLE: "true"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      #KAFKA_METRIC_REPORTERS: "io.confluent.metrics.reporter.ConfluentMetricsReporter"
      #CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: "kafka-1:9092,kafka-2:9092,kafka-3:9092"
      # KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:19092,BROKER://0.0.0.0:9092
      # KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-1-external:19092,BROKER://kafka-1:9092
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:19092,SSL://0.0.0.0:19093,BROKER://0.0.0.0:9092,SSL-INT://0.0.0.0:9093,SASL-INT://0.0.0.0:9095
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-1:19092,SSL://kafka-1-external:19093,BROKER://kafka-1:9092,SSL-INT://kafka-1:9093,SASL-INT://kafka-1:9095
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,SSL:SSL,BROKER:SSL,SSL-INT:SSL,SASL-INT:SASL_SSL
      KAFKA_SASL_ENABLED_MECHANISMS: PLAIN
      KAFKA_OPTS: -Djava.security.auth.login.config=/etc/kafka/secrets/kafka-1-jaas.conf
      KAFKA_INTER_BROKER_LISTENER_NAME: BROKER
      KAFKA_SSL_KEYSTORE_FILENAME: kafka.kafka-1.keystore.pkcs12
      KAFKA_SSL_KEYSTORE_CREDENTIALS: kafka-1_keystore_creds
      KAFKA_SSL_KEY_CREDENTIALS: kafka-1_sslkey_creds
      KAFKA_SSL_TRUSTSTORE_FILENAME: kafka.kafka-1.truststore.pkcs12
      KAFKA_SSL_TRUSTSTORE_CREDENTIALS: kafka-1_truststore_creds
      KAFKA_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM: "HTTPS"
      KAFKA_SSL_CLIENT_AUTH: "required"

      # Schema Validation
      KAFKA_CONFLUENT_SCHEMA_REGISTRY_URL: http://schema-registry-1:18081,http://schema-registry-2:28081
#       KAFKA_CONFLUENT_SCHEMA_REGISTRY_URL: https://schema-registry-1:18085,https://schema-registry-2:28085
#       KAFKA_CONFLUENT_SSL_TRUSTSTORE_LOCATION: /etc/kafka/secrets/kafka.kafka-1.truststore.pkcs12
#       KAFKA_CONFLUENT_SSL_TRUSTSTORE_PASSWORD: confluent

  kafka-2:
    image: confluentinc/cp-server:7.1.1-1-ubi8
    restart: always
    container_name: kafka-2
    hostname: kafka-2
    ports:
      - "29092:29092"
      - "29093:29093"  
    networks:
      - tls_confluent
    volumes:
      - data-kafka-2:/var/lib/kafka/data
      - /root/belajar-confluent/tls/kafka-2-creds:/etc/kafka/secrets
    environment:
      KAFKA_BROKER_ID: 102
      KAFKA_ZOOKEEPER_CONNECT: zk-1:12181,zk-2:22181,zk-3:32181
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_DELETE_TOPIC_ENABLE: "true"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      #KAFKA_METRIC_REPORTERS: "io.confluent.metrics.reporter.ConfluentMetricsReporter"
      #CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: "kafka-1:9092,kafka-2:9092,kafka-3:9092"
      # KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:29092,BROKER://0.0.0.0:9092
      # KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-2-external:29092,BROKER://kafka-2:9092
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:29092,SSL://0.0.0.0:29093,BROKER://0.0.0.0:9092,SSL-INT://0.0.0.0:9093,SASL-INT://0.0.0.0:9095
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-2:29092,SSL://kafka-2-external:29093,BROKER://kafka-2:9092,SSL-INT://kafka-2:9093,SASL-INT://kafka-2:9095
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,SSL:SSL,BROKER:SSL,SSL-INT:SSL,SASL-INT:SASL_SSL
      KAFKA_SASL_ENABLED_MECHANISMS: PLAIN
      KAFKA_OPTS: -Djava.security.auth.login.config=/etc/kafka/secrets/kafka-1-jaas.conf  
      KAFKA_INTER_BROKER_LISTENER_NAME: BROKER
      KAFKA_SSL_KEYSTORE_FILENAME: kafka.kafka-2.keystore.pkcs12
      KAFKA_SSL_KEYSTORE_CREDENTIALS: kafka-2_keystore_creds
      KAFKA_SSL_KEY_CREDENTIALS: kafka-2_sslkey_creds
      KAFKA_SSL_TRUSTSTORE_FILENAME: kafka.kafka-2.truststore.pkcs12
      KAFKA_SSL_TRUSTSTORE_CREDENTIALS: kafka-2_truststore_creds
      KAFKA_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM: "HTTPS"
      KAFKA_SSL_CLIENT_AUTH: "required"

      # Schema Validation
      KAFKA_CONFLUENT_SCHEMA_REGISTRY_URL: http://schema-registry-1:18081,http://schema-registry-2:28081
#       KAFKA_CONFLUENT_SCHEMA_REGISTRY_URL: https://schema-registry-1:18085,https://schema-registry-2:28085
#       KAFKA_CONFLUENT_SSL_TRUSTSTORE_LOCATION: /etc/kafka/secrets/kafka.kafka-1.truststore.pkcs12
#       KAFKA_CONFLUENT_SSL_TRUSTSTORE_PASSWORD: confluent

  kafka-3:
    image: confluentinc/cp-server:7.1.1-1-ubi8
    restart: always
    container_name: kafka-3
    hostname: kafka-3
    ports:
      - "39092:39092"
      - "39093:39093"  
    networks:
      - tls_confluent
    volumes:
      - data-kafka-3:/var/lib/kafka/data
      - /root/belajar-confluent/tls/kafka-3-creds:/etc/kafka/secrets
    environment:
      KAFKA_BROKER_ID: 103
      KAFKA_ZOOKEEPER_CONNECT: zk-1:12181,zk-2:22181,zk-3:32181
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_DELETE_TOPIC_ENABLE: "true"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      #KAFKA_METRIC_REPORTERS: "io.confluent.metrics.reporter.ConfluentMetricsReporter"
      #CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: "kafka-1:9092,kafka-2:9092,kafka-3:9092"
      # KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:39092,BROKER://0.0.0.0:9092
      # KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-3-external:39092,BROKER://kafka-3:9092
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:39092,SSL://0.0.0.0:39093,BROKER://0.0.0.0:9092,SSL-INT://0.0.0.0:9093,SASL-INT://0.0.0.0:9095
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-3:39092,SSL://kafka-3-external:39093,BROKER://kafka-3:9092,SSL-INT://kafka-3:9093,SASL-INT://kafka-3:9095
      KAFKA_SASL_ENABLED_MECHANISMS: PLAIN
      KAFKA_OPTS: -Djava.security.auth.login.config=/etc/kafka/secrets/kafka-1-jaas.conf  
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,SSL:SSL,BROKER:SSL,SSL-INT:SSL,SASL-INT:SASL_SSL
      KAFKA_INTER_BROKER_LISTENER_NAME: BROKER
      KAFKA_SSL_KEYSTORE_FILENAME: kafka.kafka-3.keystore.pkcs12
      KAFKA_SSL_KEYSTORE_CREDENTIALS: kafka-3_keystore_creds
      KAFKA_SSL_KEY_CREDENTIALS: kafka-3_sslkey_creds
      KAFKA_SSL_TRUSTSTORE_FILENAME: kafka.kafka-3.truststore.pkcs12
      KAFKA_SSL_TRUSTSTORE_CREDENTIALS: kafka-3_truststore_creds
      KAFKA_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM: "HTTPS"
      KAFKA_SSL_CLIENT_AUTH: "required"

      # Schema Validation
      KAFKA_CONFLUENT_SCHEMA_REGISTRY_URL: http://schema-registry-1:18081,http://schema-registry-2:28081
#       KAFKA_CONFLUENT_SCHEMA_REGISTRY_URL: https://schema-registry-1:18085,https://schema-registry-2:28085
#       KAFKA_CONFLUENT_SSL_TRUSTSTORE_LOCATION: /etc/kafka/secrets/kafka.kafka-1.truststore.pkcs12
#       KAFKA_CONFLUENT_SSL_TRUSTSTORE_PASSWORD: confluent


  schema-registry-1:
    image: confluentinc/cp-schema-registry:7.1.1-1-ubi8
    hostname: schema-registry-1
    container_name: schema-registry-1
    restart: always
    depends_on:
      - kafka-1
      - kafka-2
      - kafka-3
    ports:
      - "18081:18081"
      - "18085:18085"
    networks:
      - tls_confluent
    volumes:
      - /root/belajar-confluent/tls/schema-registry-1-creds:/etc/schema-registry/secrets
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry-1

      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: "kafka-1:19092,kafka-2:29092,kafka-3:39092"

      SCHEMA_REGISTRY_LISTENERS: "http://schema-registry-1:18081"
#      SCHEMA_REGISTRY_LISTENERS: "https://schema-registry-1:18085"

#      SCHEMA_REGISTRY_SSL_TRUSTSTORE_LOCATION: /etc/schema-registry/secrets/kafka.schema-registry-1.truststore.pkcs12
#      SCHEMA_REGISTRY_SSL_TRUSTSTORE_PASSWORD: confluent
#      SCHEMA_REGISTRY_SSL_KEYSTORE_LOCATION: /etc/schema-registry/secrets/kafka.schema-registry-1.keystore.pkcs12
#      SCHEMA_REGISTRY_SSL_KEYSTORE_PASSWORD: confluent
#      SCHEMA_REGISTRY_SSL_KEY_PASSWORD: confluent

      SCHEMA_REGISTRY_SCHEMA_REGISTRY_INTER_INSTANCE_PROTOCOL: "http"
#       SCHEMA_REGISTRY_SCHEMA_REGISTRY_INTER_INSTANCE_PROTOCOL: "https"

#       The default value for authentication.method is "NONE"

      SCHEMA_REGISTRY_CUB_KAFKA_TIMEOUT: 120
      SCHEMA_REGISTRY_CUB_KAFKA_MIN_BROKERS: 3

  schema-registry-2:
    image: confluentinc/cp-schema-registry:7.1.1-1-ubi8
    hostname: schema-registry-2
    container_name: schema-registry-2
    restart: always
    depends_on:
      - kafka-1
      - kafka-2
      - kafka-3
    ports:
      - "28081:28081"
      - "28085:28085"
    networks:
      - tls_confluent
    volumes:
      - /root/belajar-confluent/tls/schema-registry-2-creds:/etc/schema-registry/secrets
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry-2

      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: "kafka-1:19092,kafka-2:29092,kafka-3:39092"

      SCHEMA_REGISTRY_LISTENERS: "http://schema-registry-2:28081"
#      SCHEMA_REGISTRY_LISTENERS: "https://schema-registry-2:28085"

#      SCHEMA_REGISTRY_SSL_TRUSTSTORE_LOCATION: /etc/schema-registry/secrets/kafka.schema-registry-2.truststore.pkcs12
#      SCHEMA_REGISTRY_SSL_TRUSTSTORE_PASSWORD: confluent
#      SCHEMA_REGISTRY_SSL_KEYSTORE_LOCATION: /etc/schema-registry/secrets/kafka.schema-registry-2.keystore.pkcs12
#      SCHEMA_REGISTRY_SSL_KEYSTORE_PASSWORD: confluent
#      SCHEMA_REGISTRY_SSL_KEY_PASSWORD: confluent

      SCHEMA_REGISTRY_SCHEMA_REGISTRY_INTER_INSTANCE_PROTOCOL: "http"
#      SCHEMA_REGISTRY_SCHEMA_REGISTRY_INTER_INSTANCE_PROTOCOL: "https"

#      The default value for authentication.method is "NONE"

      SCHEMA_REGISTRY_CUB_KAFKA_TIMEOUT: 120
      SCHEMA_REGISTRY_CUB_KAFKA_MIN_BROKERS: 3
  
  restproxy:
    image: confluentinc/cp-kafka-rest:7.1.1-1-ubi8
    hostname: restproxy
    container_name: restproxy
    restart: always
    depends_on:
      - kafka-1
      - kafka-2
      - kafka-3
      - schema-registry-1
      - schema-registry-2
    volumes:
      - /root/belajar-confluent/tls/restproxy-creds:/etc/restproxy/secrets
    ports:
      - 8086:8086
    networks:
      - tls_confluent
    environment:
      KAFKA_REST_HOST_NAME: restproxy
      KAFKA_REST_BOOTSTRAP_SERVERS: SSL-INT://kafka-1:9093,SSL-INT://kafka-2:9093
      KAFKA_REST_LISTENERS: https://0.0.0.0:8086
      KAFKA_REST_ADVERTISED_LISTENERS: https://restproxy-external:8086

      KAFKA_REST_SCHEMA_REGISTRY_URL: http://schema-registry-1:18081,http://schema-registry-2:28081
#      KAFKA_REST_SCHEMA_REGISTRY_URL: https://schema-registry-1:18085,http://schema-registry-2:28085
#      KAFKA_REST_SCHEMA_REGISTRY_SSL_TRUSTSTORE_LOCATION: /etc/restproxy/secrets/kafka.restproxy.truststore.pkcs12
#      KAFKA_REST_SCHEMA_REGISTRY_SSL_TRUSTSTORE_PASSWORD: confluent

      KAFKA_REST_SSL_TRUSTSTORE_LOCATION: /etc/restproxy/secrets/kafka.restproxy.truststore.pkcs12
      KAFKA_REST_SSL_TRUSTSTORE_PASSWORD: confluent
      KAFKA_REST_SSL_KEYSTORE_LOCATION: /etc/restproxy/secrets/kafka.restproxy.keystore.pkcs12
      KAFKA_REST_SSL_KEYSTORE_PASSWORD: confluent
      KAFKA_REST_SSL_KEY_PASSWORD: confluent
      KAFKA_REST_SSL_CLIENT_AUTHENTICATION: 'NONE'

      KAFKA_REST_CLIENT_SECURITY_PROTOCOL: SSL
      KAFKA_REST_CLIENT_SSL_TRUSTSTORE_LOCATION: /etc/restproxy/secrets/kafka.restproxy.truststore.pkcs12
      KAFKA_REST_CLIENT_SSL_TRUSTSTORE_PASSWORD: confluent
      KAFKA_REST_CLIENT_SSL_KEYSTORE_LOCATION: /etc/restproxy/secrets/kafka.restproxy.keystore.pkcs12
      KAFKA_REST_CLIENT_SSL_KEYSTORE_PASSWORD: confluent
      KAFKA_REST_CLIENT_SSL_KEY_PASSWORD: confluent

volumes:
  data-zk-log-1:
  data-zk-data-1:
  data-zk-log-2:
  data-zk-data-2:
  data-zk-log-3:
  data-zk-data-3:
  data-kafka-1:
  data-kafka-2:
  data-kafka-3:

networks:
  tls_confluent:
    external:
        name: tls_confluent
```

Buat file `kafka-1-jaas.conf`, `kafka-2-jaas.conf`, `kafka-3-jaas.conf` di folder kafka creds:

```
KafkaServer {
   org.apache.kafka.common.security.plain.PlainLoginModule required
   username="kafkabroker"
   password="kafkabroker-secret";
};

Client {
   org.apache.zookeeper.server.auth.DigestLoginModule required
   username="kafka"
   password="kafka-secret";
};
```

Buat file `zk-jaas.conf` di folder `zk-creds`:

```
Server {
       org.apache.zookeeper.server.auth.DigestLoginModule required
       user_super="admin-secret"
       user_kafka="kafka-secret";
};
```

Buat broker keystore dan truststore untuk restproxy. Ikuti langkah-langkah di file sebelumnya.

Tambahkan line berikut di `etc/hosts`:

```
127.0.0.1       schema-registry-1
127.0.0.1       schema-registry-2
127.0.0.1       restproxy
```

Jalankan docker compose:

```
docker compose -f /root/belajar-confluent/tls/docker-compose.yaml up -d
```

Buat topic baru:

```
kafka-topics --bootstrap-server kafka-1-external:19093 \
     --create \
     --partitions 1 \
     --replication-factor 1 \
     --topic users \
     --command-config /root/belajar-confluent/tls/client-creds/client-ssl.properties
```

Jalankan command berikut:

```
schema='{
    "type":"record",
    "namespace": "example.avro",
    "name":"user",
    "fields":[{"name":"name","type":"string"},
              {"name":"age","type":"int"}]
  }' && \
kafka-avro-console-producer --bootstrap-server kafka-1-external:19093 \
    --topic users \
    --producer.config /root/belajar-confluent/tls/client-creds/client-ssl.properties \
    --property schema.registry.url=http://schema-registry-1:18081 \
    --property value.schema="${schema}"
```

![image](https://github.com/ivynajohansen/belajar-confluent/assets/83331802/909d3cdd-5eeb-4294-a490-3aede6ea7019)

Berdasarkan gambar di atas, data yang diproduce akan ditolak dan producer console akan langsung berhenti jika tidak sesuai dengan schema yang ditentukan.

Consume data:

```
kafka-avro-console-consumer --bootstrap-server kafka-1-external:19093 \
    --topic users \
    --from-beginning \
    --consumer.config /root/belajar-confluent/tls/client-creds/client-ssl.properties \
    --property schema.registry.url=http://schema-registry-1:18081
```

Hanya data `{"name":"Betty","age":16}` yang akan muncul.

## Konfigurasikan Schema Registry untuk Memerlukan Koneksi Client HTTPS

Dalam `docker-compose.yaml`, comment dan uncomment line `SCHEMA_REGISTRY_SCHEMA_REGISTRY_INTER_INSTANCE_PROTOCOL` di schema-registry-1 dan schema-registry-2 sehingga menjadi seperti ini:

![image](https://github.com/ivynajohansen/belajar-confluent/assets/83331802/db3e4177-e4bd-4e0a-a4dc-f26d8e8c6069)

Lakukan yang sama dengan `SCHEMA_REGISTRY_LISTENERS`:

![image](https://github.com/ivynajohansen/belajar-confluent/assets/83331802/d5d9007f-6e9c-4a52-aea5-bc46fa9ee984)

Uncomment line berikut dan buat cert, keystore, dan truststore dengan langkah-langkah di file sebelumnya:

```
SCHEMA_REGISTRY_SSL_TRUSTSTORE_LOCATION: /etc/schema-registry/secrets/kafka.schema-registry-1.truststore.pkcs12
SCHEMA_REGISTRY_SSL_TRUSTSTORE_PASSWORD: confluent
SCHEMA_REGISTRY_SSL_KEYSTORE_LOCATION: /etc/schema-registry/secrets/kafka.schema-registry-1.keystore.pkcs12
SCHEMA_REGISTRY_SSL_KEYSTORE_PASSWORD: confluent
SCHEMA_REGISTRY_SSL_KEY_PASSWORD: confluent
```

Pada kafka-1, kafka-2, dan kafka-3, lakukan yang sama dengan `KAFKA_CONFLUENT_SCHEMA_REGISTRY_URL`:

![image](https://github.com/ivynajohansen/belajar-confluent/assets/83331802/b1b30abc-f5cb-4bdd-ae8f-9b5de5a6d752)

Jalankan docker compose:

```
docker compose -f /root/belajar-confluent/tls/docker-compose.yaml up -d
```

Jika kita run consumer seperti sebelumnya yang menggunakan HTTP, akan error karena sudah pindah ke HTTPS.

```
kafka-avro-console-consumer --bootstrap-server kafka-1-external:19093 \
    --topic users \
    --from-beginning \
    --consumer.config /root/belajar-confluent/tls/client-creds/client-ssl.properties \
    --property schema.registry.url=http://schema-registry-1:18081
```

Karena itu, jalankan command ini, menggunakan HTTPS:

```
kafka-avro-console-consumer --bootstrap-server kafka-1-external:19093 \
    --topic users \
    --from-beginning \
    --consumer.config /root/belajar-confluent/tls/client-creds/client-ssl.properties \
    --property schema.registry.url=https://schema-registry-1:18085 \
    --property schema.registry.ssl.truststore.location=/root/belajar-confluent/tls/client-creds/kafka.client.truststore.pkcs12 \
    --property schema.registry.ssl.truststore.password=confluent
```

## Connect ke Schema Registry dengan Basic Auth

Di `docker-compose.yaml`, tambahkan line berikut pada schema-registry-1 dan 2:

```
SCHEMA_REGISTRY_AUTHENTICATION_METHOD: "BASIC"
SCHEMA_REGISTRY_AUTHENTICATION_ROLES: "admin,developer,user,sr-user"
SCHEMA_REGISTRY_AUTHENTICATION_REALM: SchemaRegistry-Props    
SCHEMA_REGISTRY_OPTS: "-Djava.security.auth.login.config=/etc/schema-registry/secrets/schema-registry-1-jaas.conf"
```


Tambahkan konfigurasi berikut di kafka-1, kafka-2, dan kafka-3:

```
KAFKA_CONFLUENT_SSL_TRUSTSTORE_LOCATION: /etc/kafka/secrets/kafka.kafka-1.truststore.pkcs12
KAFKA_CONFLUENT_SSL_TRUSTSTORE_PASSWORD: confluent
KAFKA_CONFLUENT_BASIC_AUTH_CREDENTIALS_SOURCE: USER_INFO
KAFKA_CONFLUENT_BASIC_AUTH_USER_INFO: 'superUser:confluent'
```

Tambahkan konfigurasi berikut di restproxy:

```
KAFKA_REST_SCHEMA_REGISTRY_SSL_TRUSTSTORE_LOCATION: /etc/restproxy/secrets/kafka.restproxy.truststore.pkcs12
KAFKA_REST_SCHEMA_REGISTRY_SSL_TRUSTSTORE_PASSWORD: confluent
KAFKA_REST_SCHEMA_REGISTRY_BASIC_AUTH_CREDENTIALS_SOURCE: USER_INFO
KAFKA_REST_SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO: 'restproxy:confluent'
```



Buat file bernama `schema-registry-jetty-password` yang isinya format `<username>: <password-hash>,<role1>[,<role2>,...]` dengan cara gunakan command seperti berikut:

```
schema-registry-run-class org.eclipse.jetty.util.security.Password fred confluent
```

Akan muncul output seperti ini dan pilih salah satu metode hash:

```
OBF:1w8t1tvf1w261w8v1w1c1tvn1w8x
MD5:0d107d09f5bbe40cade3de5c71e9e9b7
CRYPT:frd5btY/mvXo6
```

Isi `schema-registry-jetty-password` akan menjadi seperti berikut:

```
fred: OBF:1vn21wu81uvc1wfk1vun1wge1uuu1wu61vo0,user,admin
barney: CRYPT:bafHXQfFa4MUI,user,developer
betty: MD5:cb07cdf9204affbc2562b7d0f0d0165a,user
wilma: OBF:1vn21wu81uvc1wfk1vun1wge1uuu1wu61vo0,admin,sr-user
superUser: OBF:1vn21wu81uvc1wfk1vun1wge1uuu1wu61vo0,admin
restProxy: CRYPT:re3jkeLPp6IhA,developer
```

Buat `schema-registry-1-jaas.conf` dan `schema-registry-2-jaas.conf`:

```
SchemaRegistry-Props {
  org.eclipse.jetty.jaas.spi.PropertyFileLoginModule required
  file="/etc/schema-registry/secrets/schema-registry-jetty-passwords"
  debug="false";
};
```

Jalankan docker:

```
docker compose -f /root/belajar-confluent/tls/docker-compose.yaml up -d
```

Jalankan console producer dengan schema seperti sebelumnya:

```
schema='{
    "type":"record",
    "namespace": "example.avro",
    "name":"user",
    "fields":[{"name":"name","type":"string"},
              {"name":"age","type":"int"}]
  }' && \
kafka-avro-console-producer --bootstrap-server kafka-1-external:19093 \
    --topic users \
    --producer.config /root/belajar-confluent/tls/client-creds/client-ssl.properties \
    --property schema.registry.url=https://schema-registry-1:18085 \
    --property schema.registry.ssl.truststore.location=/root/belajar-confluent/tls/client-creds/kafka.client.truststore.pkcs12 \
    --property schema.registry.ssl.truststore.password=confluent \
    --property value.schema="${schema}"
```

Saat produce data, akan error karena belum menyediakan credentials:

![image](https://github.com/ivynajohansen/belajar-confluent/assets/83331802/9e31f90e-e439-43a3-a01c-e34a07c8b463)

Karena itu, gunakan command ini:

```
schema='{
    "type":"record",
    "namespace": "example.avro",
    "name":"user",
    "fields":[{"name":"name","type":"string"},
              {"name":"age","type":"int"}]
  }' && \
kafka-avro-console-producer --bootstrap-server kafka-1-external:19093 \
    --topic users \
    --producer.config /root/belajar-confluent/tls/client-creds/client-ssl.properties \
    --property schema.registry.url=https://schema-registry-1:18085 \
    --property schema.registry.ssl.truststore.location=/root/belajar-confluent/tls/client-creds/kafka.client.truststore.pkcs12 \
    --property schema.registry.ssl.truststore.password=confluent \
    --property basic.auth.credentials.source=USER_INFO \
    --property basic.auth.user.info=barney:confluent \
    --property value.schema="${schema}"
```

## Connect ke Schema Registry dengan SSL

Ubah konfigurasi Schema Registry supaya boostrap server diubah dari listener plaintext ke listener ssl-int dan tambahkan konfigurasi `SCHEMA_REGISTRY_KAFKASTORE`:

```
# SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: "kafka-1:19092,kafka-2:29092,kafka-3:39092"
SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: "kafka-1:9093,kafka-2:9093,kafka-3:9093"

SCHEMA_REGISTRY_KAFKASTORE_SECURITY_PROTOCOL: SSL
SCHEMA_REGISTRY_KAFKASTORE_SSL_TRUSTSTORE_LOCATION: /etc/schema-registry/secrets/kafka.schema-registry-1.truststore.pkcs12
SCHEMA_REGISTRY_KAFKASTORE_SSL_TRUSTSTORE_PASSWORD: confluent
SCHEMA_REGISTRY_KAFKASTORE_SSL_KEYSTORE_LOCATION: /etc/schema-registry/secrets/kafka.schema-registry-1.keystore.pkcs12
SCHEMA_REGISTRY_KAFKASTORE_SSL_KEYSTORE_PASSWORD: confluent
SCHEMA_REGISTRY_KAFKASTORE_SSL_KEY_PASSWORD: confluent
```

Produce message ke topic:

```
schema='{
    "type":"record",
    "namespace": "example.avro",
    "name":"user",
    "fields":[{"name":"name","type":"string"},
              {"name":"age","type":"int"}]
  }' && \
kafka-avro-console-producer --bootstrap-server kafka-1-external:19093 \
    --topic users \
    --producer.config /root/belajar-confluent/tls/client-creds/client-ssl.properties \
    --property schema.registry.url=https://schema-registry-1:18085 \
    --property schema.registry.ssl.truststore.location=/root/belajar-confluent/tls/client-creds/kafka.client.truststore.pkcs12 \
    --property schema.registry.ssl.truststore.password=confluent \
    --property basic.auth.credentials.source=USER_INFO \
    --property basic.auth.user.info=barney:confluent \
    --property value.schema="${schema}"
```

```
{"name":"David","favorite_number":33,"age":11}
```

Konfirmasi bahwa schema telah dibuat:

```
docker compose -f /root/belajar-confluent/tls/docker-compose.yaml logs schema-registry-1 | grep "Registering new schema\|offset at"
```

![image](https://github.com/ivynajohansen/belajar-confluent/assets/83331802/f70c3b0e-de75-41f6-857d-0559ee3fe9b3)


Pastikan bahwa message baru yang dikirim lewat SSL telah ada di topic:

```
kafka-avro-console-consumer --bootstrap-server kafka-1-external:19093 \
    --topic users \
    --from-beginning \
    --consumer.config /root/belajar-confluent/tls/client-creds/client-ssl.properties \
    --property schema.registry.url=https://schema-registry-1:18085 \
    --property schema.registry.ssl.truststore.location=/root/belajar-confluent/tls/client-creds/kafka.client.truststore.pkcs12 \
    --property schema.registry.ssl.truststore.password=confluent \
    --property basic.auth.credentials.source=USER_INFO \
    --property basic.auth.user.info=barney:confluent
```

![image](https://github.com/ivynajohansen/belajar-confluent/assets/83331802/8733b628-4d02-457f-96da-2f4df8a9fd28)

## Connect ke Schema Registry dengan SASL
