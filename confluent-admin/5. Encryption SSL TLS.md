# Encryption SSL/TLS

## Setup Docker

Untuk membuat cluster kafka dengan 3 broker, install docker supaya setiap broker bisa ditampung di docker container yang berbeda-beda tetapi tetap dalam 1 server.

### Install Docker

Pertama, tambahkan official GPG key Docker.

```
sudo apt-get update
sudo apt-get install ca-certificates curl
sudo install -m 0755 -d /etc/apt/keyrings
sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc
sudo chmod a+r /etc/apt/keyrings/docker.asc
```

Tambahkan repository ke Apt sources:

```
echo \
  "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \
  $(. /etc/os-release && echo "$VERSION_CODENAME") stable" | \
  sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
sudo apt-get update
```

Install Docker.

```
sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin
```

### Setup Kafka di Docker

Buat docker-compose.yaml yang isinya seperti berikut:

```
version: "3.5"
services:
  zk-1:
    image: confluentinc/cp-zookeeper:7.1.1-1-ubi8
    restart: always
    container_name: zk-1
    hostname: zk-1
    ports:
      - "12181:12181"
    volumes:
      - data-zk-log-1:/var/lib/zookeeper/log
      - data-zk-data-1:/var/lib/zookeeper/data
    networks:
      - confluent
    environment:
      - ZOOKEEPER_SERVER_ID=1
      - ZOOKEEPER_CLIENT_PORT=12181
      - ZOOKEEPER_TICK_TIME=2000
      - ZOOKEEPER_INIT_LIMIT=5
      - ZOOKEEPER_SYNC_LIMIT=2
      - ZOOKEEPER_SERVERS=zk-1:2888:3888;zk-2:2888:3888;zk-3:2888:3888
  
  zk-2:
    image: confluentinc/cp-zookeeper:7.1.1-1-ubi8
    restart: always
    container_name: zk-2
    hostname: zk-2
    ports:
      - "22181:22181"
    volumes:
      - data-zk-log-2:/var/lib/zookeeper/log
      - data-zk-data-2:/var/lib/zookeeper/data
    networks:
      - confluent
    environment:
      - ZOOKEEPER_SERVER_ID=2
      - ZOOKEEPER_CLIENT_PORT=22181
      - ZOOKEEPER_TICK_TIME=2000
      - ZOOKEEPER_INIT_LIMIT=5
      - ZOOKEEPER_SYNC_LIMIT=2
      - ZOOKEEPER_SERVERS=zk-1:2888:3888;zk-2:2888:3888;zk-3:2888:3888
  
  zk-3:
    image: confluentinc/cp-zookeeper:7.1.1-1-ubi8
    restart: always
    container_name: zk-3
    hostname: zk-3
    ports:
      - "32181:32181"
    volumes:
      - data-zk-log-3:/var/lib/zookeeper/log
      - data-zk-data-3:/var/lib/zookeeper/data
    networks:
      - confluent
    environment:
      - ZOOKEEPER_SERVER_ID=3
      - ZOOKEEPER_CLIENT_PORT=32181
      - ZOOKEEPER_TICK_TIME=2000
      - ZOOKEEPER_INIT_LIMIT=5
      - ZOOKEEPER_SYNC_LIMIT=2
      - ZOOKEEPER_SERVERS=zk-1:2888:3888;zk-2:2888:3888;zk-3:2888:3888

  kafka-1:
    image: confluentinc/cp-server:7.1.1-1-ubi8
    restart: always
    container_name: kafka-1
    hostname: kafka-1
    ports:
      - "19092:19092"
      - "19093:19093"      
    networks:
      - confluent
    volumes:
      - data-kafka-1:/var/lib/kafka/data
      - /root/belajar-confluent/tls/kafka-1-creds:/etc/kafka/secrets
    environment:
      KAFKA_BROKER_ID: 101
      KAFKA_ZOOKEEPER_CONNECT: zk-1:12181,zk-2:22181,zk-3:32181
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_DELETE_TOPIC_ENABLE: "true"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      #KAFKA_METRIC_REPORTERS: "io.confluent.metrics.reporter.ConfluentMetricsReporter"
      #CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: "kafka-1:9092,kafka-2:9092,kafka-3:9092"
      # KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:19092,BROKER://0.0.0.0:9092
      # KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-1-external:19092,BROKER://kafka-1:9092
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:19092,SSL://0.0.0.0:19093,BROKER://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-1-external:19092,SSL://kafka-1-external:19093,BROKER://kafka-1:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,SSL:SSL,BROKER:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: BROKER
      KAFKA_SSL_KEYSTORE_FILENAME: kafka.kafka-1.keystore.pkcs12
      KAFKA_SSL_KEYSTORE_CREDENTIALS: kafka-1_keystore_creds
      KAFKA_SSL_KEY_CREDENTIALS: kafka-1_sslkey_creds
      # KAFKA_SSL_TRUSTSTORE_FILENAME: kafka.kafka-1.truststore.jks
      # KAFKA_SSL_TRUSTSTORE_CREDENTIALS: kafka-1_truststore_creds
      KAFKA_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM: "HTTPS"
      #KAFKA_SSL_CLIENT_AUTH: "required"

  kafka-2:
    image: confluentinc/cp-server:7.1.1-1-ubi8
    restart: always
    container_name: kafka-2
    hostname: kafka-2
    ports:
      - "29092:29092"
      - "29093:29093"  
    networks:
      - confluent
    volumes:
      - data-kafka-2:/var/lib/kafka/data
      - /root/belajar-confluent/tls/kafka-2-creds:/etc/kafka/secrets
    environment:
      KAFKA_BROKER_ID: 102
      KAFKA_ZOOKEEPER_CONNECT: zk-1:12181,zk-2:22181,zk-3:32181
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_DELETE_TOPIC_ENABLE: "true"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      #KAFKA_METRIC_REPORTERS: "io.confluent.metrics.reporter.ConfluentMetricsReporter"
      #CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: "kafka-1:9092,kafka-2:9092,kafka-3:9092"
      # KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:29092,BROKER://0.0.0.0:9092
      # KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-2-external:29092,BROKER://kafka-2:9092
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:29092,SSL://0.0.0.0:29093,BROKER://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-2-external:29092,SSL://kafka-2-external:29093,BROKER://kafka-2:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,SSL:SSL,BROKER:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: BROKER
      KAFKA_SSL_KEYSTORE_FILENAME: kafka.kafka-2.keystore.pkcs12
      KAFKA_SSL_KEYSTORE_CREDENTIALS: kafka-2_keystore_creds
      KAFKA_SSL_KEY_CREDENTIALS: kafka-2_sslkey_creds
      # KAFKA_SSL_TRUSTSTORE_FILENAME: kafka.kafka-2.truststore.jks
      # KAFKA_SSL_TRUSTSTORE_CREDENTIALS: kafka-2_truststore_creds
      KAFKA_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM: "HTTPS"
      #KAFKA_SSL_CLIENT_AUTH: "required"

  kafka-3:
    image: confluentinc/cp-server:7.1.1-1-ubi8
    restart: always
    container_name: kafka-3
    hostname: kafka-3
    ports:
      - "39092:39092"
      - "39093:39093"  
    networks:
      - confluent
    volumes:
      - data-kafka-3:/var/lib/kafka/data
      - /root/belajar-confluent/tls/kafka-3-creds:/etc/kafka/secrets
    environment:
      KAFKA_BROKER_ID: 103
      KAFKA_ZOOKEEPER_CONNECT: zk-1:12181,zk-2:22181,zk-3:32181
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_DELETE_TOPIC_ENABLE: "true"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      #KAFKA_METRIC_REPORTERS: "io.confluent.metrics.reporter.ConfluentMetricsReporter"
      #CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: "kafka-1:9092,kafka-2:9092,kafka-3:9092"
      # KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:39092,BROKER://0.0.0.0:9092
      # KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-3-external:39092,BROKER://kafka-3:9092
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:39092,SSL://0.0.0.0:39093,BROKER://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-3-external:39092,SSL://kafka-3-external:39093,BROKER://kafka-3:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,SSL:SSL,BROKER:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: BROKER
      KAFKA_SSL_KEYSTORE_FILENAME: kafka.kafka-3.keystore.pkcs12
      KAFKA_SSL_KEYSTORE_CREDENTIALS: kafka-3_keystore_creds
      KAFKA_SSL_KEY_CREDENTIALS: kafka-3_sslkey_creds
      # KAFKA_SSL_TRUSTSTORE_FILENAME: kafka.kafka-3.truststore.jks
      # KAFKA_SSL_TRUSTSTORE_CREDENTIALS: kafka-3_truststore_creds
      KAFKA_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM: "HTTPS"
      #KAFKA_SSL_CLIENT_AUTH: "required"

volumes:
  data-zk-log-1:
  data-zk-data-1:
  data-zk-log-2:
  data-zk-data-2:
  data-zk-log-3:
  data-zk-data-3:
  data-kafka-1:
  data-kafka-2:
  data-kafka-3:

networks:
  confluent:
```

Perhatikan line berikut:

```
KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:19092,SSL://0.0.0.0:19093,BROKER://0.0.0.0:9092
KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-1-external:19092,SSL://kafka-1-external:19093,BROKER://kafka-1:9092
```

Listener SSL telah ditambahkan ke port 19093

## Broker Keystore

1. Buat file `ca.cnf` di folder baru `tls` yang isinya:

```
[ policy_match ]
countryName = match
stateOrProvinceName = match
organizationName = match
organizationalUnitName = optional
commonName = supplied
emailAddress = optional

[ req ]
prompt = no
distinguished_name = dn
default_md = sha256
default_bits = 4096
x509_extensions = v3_ca

[ dn ]
countryName = US
organizationName = Confluent
localityName = MountainView
commonName = confluent-ca

[ v3_ca ]
subjectKeyIdentifier=hash
basicConstraints = critical,CA:true
authorityKeyIdentifier=keyid:always,issuer:always
keyUsage = critical,keyCertSign,cRLSign
```

2. Buat Certification Authority (CA) key & certificate

```
openssl req -new -nodes \
   -x509 \
   -days 365 \
   -newkey rsa:2048 \
   -keyout /root/belajar-confluent/tls/ca.key \
   -out /root/belajar-confluent/tls/ca.crt \
   -config /root/belajar-confluent/tls/ca.cnf
```

3. Convert key CA ke format pem

```
cat /root/belajar-confluent/tls/ca.crt /root/belajar-confluent/tls/ca.key > /root/belajar-confluent/tls/ca.pem
```

4. Buat file bernama kafka-1.creds, kafka-2.creds, kafka-3.creds yang isinya seperti berikut:

```
[req]
prompt = no
distinguished_name = dn
default_md = sha256
default_bits = 4096
req_extensions = v3_req

[ dn ]
countryName = US
organizationName = CONFLUENT
localityName = MountainView
commonName=kafka-1

[ v3_ca ]
subjectKeyIdentifier=hash
basicConstraints = critical,CA:true
authorityKeyIdentifier=keyid:always,issuer:always
keyUsage = critical,keyCertSign,cRLSign

[ v3_req ]
subjectKeyIdentifier = hash
basicConstraints = CA:FALSE
nsComment = "OpenSSL Generated Certificate"
keyUsage = critical, digitalSignature, keyEncipherment
extendedKeyUsage = serverAuth, clientAuth
subjectAltName = @alt_names

[ alt_names ]
DNS.1=kafka-1
DNS.2=kafka-1-external
```

> Ubah 'kafka-1' ke 'kafka-2'/'kafka-3' berdasarkan file masing-masing

5. Jalankan command berikut untuk buat server key & certificate signing request (file .csr):

```
openssl req -new \
    -newkey rsa:2048 \
    -keyout /root/belajar-confluent/tls/kafka-1-creds/kafka-1.key \
    -out /root/belajar-confluent/tls/kafka-1-creds/kafka-1.csr \
    -config /root/belajar-confluent/tls/kafka-1-creds/kafka-1.cnf \
    -nodes
```

6. Sign server dengan sertifikat CA:

```
openssl x509 -req \
    -days 3650 \
    -in /root/belajar-confluent/tls/kafka-1-creds/kafka-1.csr \
    -CA /root/belajar-confluent/tls/ca.crt \
    -CAkey /root/belajar-confluent/tls/ca.key \
    -CAcreateserial \
    -out /root/belajar-confluent/tls/kafka-1-creds/kafka-1.crt \
    -extfile /root/belajar-confluent/tls/kafka-1-creds/kafka-1.cnf \
    -extensions v3_req
```

![image](https://github.com/ivynajohansen/belajar-confluent/assets/83331802/9ac9a513-d37a-4079-a4ad-9a857e3e0949)

7. Convert sertifikat server ke format pkcs12:

```
openssl pkcs12 -export \
    -in /root/belajar-confluent/tls/kafka-1-creds/kafka-1.crt \
    -inkey /root/belajar-confluent/tls/kafka-1-creds/kafka-1.key \
    -chain \
    -CAfile /root/belajar-confluent/tls/ca.pem \
    -name kafka-1 \
    -out /root/belajar-confluent/tls/kafka-1-creds/kafka-1.p12 \
    -password pass:confluent
```

8. Buat broker keystore:

```
sudo keytool -importkeystore \
    -deststorepass confluent \
    -destkeystore /root/belajar-confluent/tls/kafka-1-creds/kafka.kafka-1.keystore.pkcs12 \
    -srckeystore /root/belajar-confluent/tls/kafka-1-creds/kafka-1.p12 \
    -deststoretype PKCS12  \
    -srcstoretype PKCS12 \
    -noprompt \
    -srcstorepass confluent
```

![image](https://github.com/ivynajohansen/belajar-confluent/assets/83331802/263d240d-3666-4d84-b564-b3fc4866a826)

9. Verifikasi keystore broker kafka-1:

```
keytool -list -v \
    -keystore /root/belajar-confluent/tls/kafka-1-creds/kafka.kafka-1.keystore.pkcs12 \
    -storepass confluent
```

  Hasil akan seperti ini:

  ```
Keystore type: PKCS12
Keystore provider: SUN

Your keystore contains 1 entry

Alias name: kafka-1
Creation date: Jun 24, 2024
Entry type: PrivateKeyEntry
Certificate chain length: 2
Certificate[1]:
Owner: CN=kafka-1, L=MountainView, O=CONFLUENT, C=US
Issuer: CN=confluent-ca, L=MountainView, O=Confluent, C=US
Serial number: 7588e4fb3f46b3ce41f6ed10afb6c3a1d65419a4
Valid from: Mon Jun 24 09:46:04 UTC 2024 until: Thu Jun 22 09:46:04 UTC 2034
Certificate fingerprints:
         SHA1: 58:D6:15:85:DA:13:80:C2:0C:32:12:60:AE:DD:47:87:74:FE:D4:D4
         SHA256: 41:35:90:86:1D:2E:75:7A:06:4B:8B:0D:C5:BA:20:71:C6:56:1D:96:55:7D:3F:8A:62:DB:71:84:B9:13:A1:03
Signature algorithm name: SHA256withRSA
Subject Public Key Algorithm: 2048-bit RSA key
Version: 3

Extensions:

#1: ObjectId: 2.16.840.1.113730.1.13 Criticality=false
0000: 16 1D 4F 70 65 6E 53 53   4C 20 47 65 6E 65 72 61  ..OpenSSL Genera
0010: 74 65 64 20 43 65 72 74   69 66 69 63 61 74 65     ted Certificate


#2: ObjectId: 2.5.29.35 Criticality=false
AuthorityKeyIdentifier [
KeyIdentifier [
0000: 53 48 91 A7 5A 06 C2 E9   F0 34 62 5C 36 E2 C2 23  SH..Z....4b\6..#
0010: 77 A5 8F 7A                                        w..z
]
]

#3: ObjectId: 2.5.29.19 Criticality=false
BasicConstraints:[
  CA:false
  PathLen: undefined
]

#4: ObjectId: 2.5.29.37 Criticality=false
ExtendedKeyUsages [
  serverAuth
  clientAuth
]

#5: ObjectId: 2.5.29.15 Criticality=true
KeyUsage [
  DigitalSignature
  Key_Encipherment
]

#6: ObjectId: 2.5.29.17 Criticality=false
SubjectAlternativeName [
  DNSName: kafka-1
  DNSName: kafka-1-external
]

#7: ObjectId: 2.5.29.14 Criticality=false
SubjectKeyIdentifier [
KeyIdentifier [
0000: C3 B7 D8 67 75 9C D3 49   27 34 E3 A5 BE EE A8 59  ...gu..I'4.....Y
0010: 7F 07 CD CE                                        ....
]
]

Certificate[2]:
Owner: CN=confluent-ca, L=MountainView, O=Confluent, C=US
Issuer: CN=confluent-ca, L=MountainView, O=Confluent, C=US
Serial number: 4ebec7d42dae6a7eed4b885649585f63d0c79c30
Valid from: Mon Jun 24 09:26:27 UTC 2024 until: Tue Jun 24 09:26:27 UTC 2025
Certificate fingerprints:
         SHA1: DB:17:BE:70:31:0E:B2:A0:A6:49:CA:35:DF:E0:DE:C4:32:88:BD:3E
         SHA256: A5:2D:56:82:17:29:95:4A:DE:9A:2E:71:E6:D0:34:C4:27:78:35:D4:8E:C5:11:7B:73:47:DE:1F:7B:A9:F2:B7
Signature algorithm name: SHA256withRSA
Subject Public Key Algorithm: 2048-bit RSA key
Version: 3

Extensions:

#1: ObjectId: 2.5.29.35 Criticality=false
AuthorityKeyIdentifier [
KeyIdentifier [
0000: 53 48 91 A7 5A 06 C2 E9   F0 34 62 5C 36 E2 C2 23  SH..Z....4b\6..#
0010: 77 A5 8F 7A                                        w..z
]
[CN=confluent-ca, L=MountainView, O=Confluent, C=US]
SerialNumber: [    4ebec7d4 2dae6a7e ed4b8856 49585f63 d0c79c30]
]

#2: ObjectId: 2.5.29.19 Criticality=true
BasicConstraints:[
  CA:true
  PathLen: no limit
]

#3: ObjectId: 2.5.29.15 Criticality=true
KeyUsage [
  Key_CertSign
  Crl_Sign
]

#4: ObjectId: 2.5.29.14 Criticality=false
SubjectKeyIdentifier [
KeyIdentifier [
0000: 53 48 91 A7 5A 06 C2 E9   F0 34 62 5C 36 E2 C2 23  SH..Z....4b\6..#
0010: 77 A5 8F 7A                                        w..z
]
]



*******************************************
*******************************************
```

10. Save crendentials `kafka-1`, yaitu passwordnya yaitu `confluent`:

```
sudo tee /root/belajar-confluent/tls/kafka-1-creds/kafka-1_sslkey_creds << EOF >/dev/null
confluent
EOF
```

```
sudo tee /root/belajar-confluent/tls/kafka-1-creds/kafka-1_keystore_creds << EOF >/dev/null
confluent
EOF
```

Credentials diatas diperlukan untuk parameter broker configuration seperti berikut:

```
KAFKA_SSL_KEYSTORE_CREDENTIALS: kafka-1_keystore_creds
KAFKA_SSL_KEY_CREDENTIALS: kafka-1_sslkey_creds
```

11. Lakukan yang sama dengan kafka-2 dan kafka-3.

## Pastikan SSL Diaktifkan di Kafka Broker

Start kafka cluster:

```
docker compose -f /root/belajar-confluent/tls/docker-compose.yaml up -d
```

Pastikan instance Zookeeper dan broker Kafka berjalan:

```
docker compose -f /root/belajar-confluent/tls/docker-compose.yaml ps
```

Navigasi ke `/etc/hosts` dan tambahkan line berikut:

```
# Hosts for Confluent Training
127.0.0.1       kafka-1-external
127.0.0.1       kafka-2-external
127.0.0.1       kafka-3-external
127.0.0.1       zk-1
127.0.0.1       zk-2
127.0.0.1       zk-3
```

Open SSL connection dengan broker kafka-1:

```
openssl s_client -connect kafka-1-external:19093 -tls1_3 -showcerts
```

Hasilnya akan seperti ini:

![image](https://github.com/ivynajohansen/belajar-confluent/assets/83331802/8d6f1557-e0bc-4f1c-be5e-05cce4116914)

Lakukan yang sama ke listener SSL broker kafka-2 dan kafka-3.

## Encrypt Client

Buat topic baru di dalam kafka-1-external:

```
kafka-topics \
    --bootstrap-server kafka-1-external:19092 \
    --create \
    --topic test-topic \
    --replica-assignment 101:102:103
```

Jalankan command berikut untuk inspect TCP packets di port 19092 dan 19093 container kafka-1.

```
docker run --rm -it --net container:kafka-1  \
    nicolaka/netshoot  \
        tcpdump -c 40 -X port 19092 or port 19093
```

Produce 1 message berisi `PLAINTEXT_record` dalam kafka-console-producer:

```
kafka-console-producer \
    --bootstrap-server kafka-1-external:19092 \
    --topic test-topic
```

Message yang diproduce ke topic test-topic bisa terlihat dengan jelas tanpa enkripsi seperti gambar dibawah:

![image](https://github.com/ivynajohansen/belajar-confluent/assets/83331802/656c198f-9acc-4792-ae6c-7d72206da4f1)

### Client Truststore

Jalankan command berikut untuk buat client truststore dan import CA cert:

```
sudo keytool -keystore /root/belajar-confluent/tls/client-creds/kafka.client.truststore.pkcs12 \
    -alias CARoot \
    -import \
    -file /root/belajar-confluent/tls/ca.crt \
    -storepass confluent  \
    -noprompt \
    -storetype PKCS12
```

Sekarang jika ingin produce data di port 19093, error akan muncul karena client perlu konfigurasi credential. Karena itu, buat file bernama `client-ssl.properties` yang isinya:

```
security.protocol = SSL
ssl.truststore.location=/root/belajar-confluent/tls/client-creds/kafka.client.truststore.pkcs12
ssl.truststore.password=confluent
```

Jalankan producer console di port 19093 dengan konfigurasi lalu produce data lagi:

```
kafka-console-producer \
    --bootstrap-server kafka-1-external:19093 \
    --topic test-topic \
    --producer.config /root/belajar-confluent/tls/client-creds/client-ssl.properties
```

![image](https://github.com/ivynajohansen/belajar-confluent/assets/83331802/d2fdd641-cf04-4c01-91ea-04d4ff5d7960)

Kali ini, message yang dikirim telah dienkripsi sehingga tidak terlihat. Coba consume dengan console consumer:

```
kafka-console-consumer \
    --bootstrap-server kafka-1-external:19093 \
    --topic test-topic \
    --consumer.config /root/belajar-confluent/tls/client-creds/client-ssl.properties \
    --from-beginning
```

![image](https://github.com/ivynajohansen/belajar-confluent/assets/83331802/c1f4a501-88de-418b-b31f-2b595122460d)
