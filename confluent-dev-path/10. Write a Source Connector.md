# Write a Source Connector

## Design a Source Connector

Banyak pre-built connectors yang tersedia, baik didukung oleh Confluent, mitra, atau komunitas. Sebelum membuat connector khusus, disarankan untuk memeriksa apakah sudah ada connector untuk sumber data. Contoh-contohnya termasuk:

- FileStreamSource: menyalin data dari file ke Kafka
- JdbcSourceConnector: menyalin data dari database JDBC ke Kafka
- ActiveMQSourceConnector: menyalin data dari cluster ActiveMQ ke Kafka
  
Connector terdiri dari tasks yang dapat berjalan secara paralel, dengan setiap task mengelola subset data. Misalnya, JdbcSourceConnector dapat menyalin data dari beberapa tabel, di mana setiap tabel ditugaskan ke task yang berbeda. Task menangani data partitioning, di mana kelompok data, seperti tabel, didistribusikan di antara task untuk pemrosesan paralel yang efisien.

Menggunakan contoh di atas: JdbcSourceConnector dapat memecah pekerjaan saat menyalin aliran data dari beberapa tabel. Karena ini merupakan pola yang umum dalam konektor, kita dapat menggunakan metode ConnectorUtils#groupPartitions untuk menetapkan kelompok partisi ke tugas.

```
int maxTasks = 3;
List<String> tableNames = Arrays.asList("departments", "employees", "dept_emp", "dept_manager", "titles", "salaries");
List<List<String>> groups = ConnectorUtils.groupPartitions(tableNames, maxTasks);
System.out.println(groups);
```

Yang mengembalikan

```
[[departments, employees], [dept_emp, dept_manager], [titles, salaries]]
```

![image](https://github.com/user-attachments/assets/b22af84d-1e06-4ef4-9a76-651848199393)

Manajemen offset ditangani oleh Kafka APIs, yang menyimpan posisi connector dalam aliran data dan mengambilnya kembali saat terjadi rebalance. Ini memastikan bahwa connector mengetahui dari mana harus memulai ulang jika terjadi gangguan.

## Write a Source Connector

### SourceConnector
Kode konektor berada dalam kelas yang berasal dari SourceConnector. Metode abstrak yang penting dijelaskan di bawah ini.

- `void start(Map<String, String> props)` kode konektor menerima konfigurasi dalam metode start.

- `List<Map<String, String>> taskConfigs(int maxTasks)` kode mengembalikan daftar pengaturan konfigurasi task hingga nomor maxTasks. Di sinilah putuskan cara mempartisi penyalinan data.

### SourceTask
Task yang menyalin data berasal dari SourceTask.

- `void start(Map<String, String> props)` kode tugas Anda menerima konfigurasi yang dibuat di SourceConnector#taskConfigs dalam metode start.

- `List<SourceRecord> poll()` Connect "polling" task untuk data baru.

### Copying Data

Di dalam metode poll(), kode mengembalikan daftar kelas SourceRecord yang diisi dengan data yang disalin dari sumber. Kelas SourceRecord juga menetapkan offset stream pemrosesan.

```
records.add(
    new SourceRecord(offsetKey(increment),  // sourcePartition
      offsetValue(++offset),                // sourceOffset
      topic,                                // topic
      null,                                 // partition
      VALUE_SCHEMA,                         // valueSchema
      struct                                // value
    )
);
```
### Schema and Struct

Output konektor dapat berupa tipe standar Java, atau struktur data dari paket org.apache.kafka.connect.data. Jika data berupa rekaman terstruktur, bisa mengisi Struct dan menyediakan skema.

```
Schema schema = SchemaBuilder.struct().name("com.example.Person")
		.field("name", Schema.STRING_SCHEMA).field("age", Schema.INT32_SCHEMA).build();
Struct struct = new Struct(schema).put("name", "Bobby McGee").put("age", 21);
```

### Activity

Masuk ke lab environment confluent portal, lalu build jar:

```
./gradlew shadowJar
```

Nyalakan schema registry lewat docker:

```
docker-compose up -d zookeeper kafka schema-registry
```

Pastikan schema registry sudah menyala:

```
curl localhost:8081/mode
```

Jalankan worker standalone connect. Skrip connect-standalone akan menampilkan banyak informasi yang akan bergulir keluar layar.

```
connect-standalone connect-avro-standalone.properties connector1.properties
```

IncrementSourceConnector.java mencatat konfigurasi setiap tugas dengan baris ini:

```
log.info("Task config: (prefix: {}, increments {})", topicPrefix, String.join(",", taskIncrements));
```

Dari window terminal baru, gunakan kafka-avro-console-consumer untuk menggunakan semua topik yang dimulai dengan seq_. Biarkan consumer ini berjalan hingga diperintahkan untuk mengakhirinya.

```
kafka-avro-console-consumer --bootstrap-server localhost:9092 --whitelist 'seq_.+'
{"threadId":37,"hostname":"training","value":3}
{"threadId":37,"hostname":"training","value":300}
{"threadId":37,"hostname":"training","value":4}
{"threadId":37,"hostname":"training","value":400}
```

Gunakan string untuk menemukan offset yang disimpan oleh IncrementSourceTask di /tmp/connect.offsets:

```
$ strings /tmp/connect.offsets
java.util.HashMap
loadFactorI
thresholdxp?@
-["kafka-connect-increment",{"increment":100}]uq
{"position":17}uq
+["kafka-connect-increment",{"increment":1}]uq
{"position":17}x
```

Jalankan kembali pekerja connect-standalone

```
$ connect-standalone connect-avro-standalone.properties connector1.properties
```

Output dari pencatatan IncrementSourceTask berisi pesan `We found an offset for increment…`​. Tugas konektor telah berhasil dilanjutkan dari offset. Kembali ke konsumer di jendela terminal sebelumnya. Amati urutan pesan telah berlanjut dari tempat sebelumnya berakhir.

## Connect Cluster and Rebalance

### Kafka Connect Distributed mode
Connect workers berjalan di beberapa node, dengan connectors dan tasks yang didistribusikan di seluruh cluster.

Menyimpan konfigurasi connector, status, dan offsets dalam topik Kafka: connect-config, connect-status, dan connect-offsets. Data dari connect tersimpan dengan aman dan direplikasi di topik Kafka, sehingga ketika terjadi kegagalan pada connect worker, tidak ada data yang hilang.

Fault tolerance - Kafka Connect dapat secara otomatis menyeimbangkan connectors dan tasks jika ada node yang gagal atau keluar dari cluster.

### Kafka Connect REST API
Mode Standalone menggunakan file untuk konfigurasi connector, sedangkan mode Distributed menggunakan REST API untuk mendistribusikan dan mengelola connectors.

REST API menyediakan informasi status, menambahkan, dan menghapus connectors.

REST API ini dapat diakses oleh semua workers dalam cluster, dan beberapa permintaan otomatis diteruskan ke leader.

### Activity

Nyalakan schema registry dan connect melalui docker:

```
docker-compose up -d zookeeper kafka schema-registry connect-1 connect-2
```

![image](https://github.com/user-attachments/assets/18264dbd-81ee-4e2e-a657-b382ed4133ae)


Service di kluster sekarang tersedia di port berikut:

| Service          | Endpoint          |
|------------------|-------------------|
| connect-1        | localhost:8083     |
| connect-2        | localhost:8084     |
| kafka            | localhost:9092     |
| schema-registry  | localhost:8081     |
| zookeeper        | localhost:2181     |

Jalankan command berikut untuk cek node worker mana yang menjadi leader:

```
docker-compose logs connect-1 | grep "leaderUrl"
```

![image](https://github.com/user-attachments/assets/322e6aa3-41a0-41b5-b5fd-af57df7be27c)

Gunakan REST API untuk menambahkan konektor IncrementSourceConnector dengan perintah curl di bawah ini:

```
curl -X POST \
  -H "Content-Type: application/json" \
  --data '{
    "name": "kafka-connect-increment",
    "config": {
      "connector.class": "com.example.IncrementSourceConnector",
      "increments": "1,100",
      "tasks.max": "3",
      "topic.prefix": "seq_",
      "key.converter": "org.apache.kafka.connect.storage.StringConverter",
      "value.converter": "io.confluent.connect.avro.AvroConverter",
      "value.converter.schema.registry.url": "http://schema-registry:8081"
    }
}' localhost:8083/connectors
```

![image](https://github.com/user-attachments/assets/6261ec29-18d4-4930-a191-f8ea57f8cc2e)

Gunakan REST API untuk mendapatkan daftar task yang saat ini berjalan untuk konektor:

```
curl -s localhost:8083/connectors/kafka-connect-increment/tasks | jq .
```

![image](https://github.com/user-attachments/assets/209ba6c8-2509-4a9e-947b-4b464093408a)

Gunakan kafka-console-consumer untuk mengamati offset yang ditulis ke topik connect-offsets:

```
kafka-console-consumer --bootstrap-server localhost:9092 \
--topic connect-offsets \
--property print.key=true
```

![image](https://github.com/user-attachments/assets/d89f81d0-0fdc-4ec5-9053-dd1de5d66d3d)

Dari window terminal baru, gunakan kafka-avro-console-consumer untuk menggunakan semua topik yang dimulai dengan seq_. Biarkan konsumen ini berjalan hingga diperintahkan untuk mengakhirinya.

```
kafka-avro-console-consumer --bootstrap-server localhost:9092 --whitelist 'seq_.+'
```

![image](https://github.com/user-attachments/assets/c9e3006b-833a-42d5-96ac-d1fd0de97e5e)

Kembali ke terminal semula dan paksakan penyeimbangan ulang dengan menghentikan pekerja connect-2:

```
docker-compose stop connect-2
```

Cek status connector:

```
curl -s localhost:8083/connectors/kafka-connect-increment/status | jq .
```

![image](https://github.com/user-attachments/assets/c9662bd2-73b8-4271-89ac-1341cb7b2ccc)

Jika connect-2 adalah leader, kita akan melihat rebalance terjadi segera karena adanya perubahan kepemimpinan ke connect-1.

Jika connect-1 adalah leader, kita akan melihat penundaan hingga 5 menit untuk rebalance, karena pengaturan default untuk scheduled.rebalance.max.delay.ms adalah 5 menit.

