# Apache Kafka Fundamentals

## Producer

![image](https://github.com/user-attachments/assets/3e17fb69-fecb-4f75-b995-0a0c1dfd6d78)

Aplikasi yang meneruskan atau menulis semua data ini ke Kafka disebut Producer.
• Producer mengirim data ke Kafka
• Producer (opsional) menerima ACK atau NACK dari Kafka
• Jika ACK (diakui) diterima, maka semuanya baik-baik saja
• Jika NACK (tidak diakui) diterima, maka Producer tahu bahwa Kafka tidak dapat menerima data karena alasan apa pun. Dalam kasus ini, Producer secara otomatis mencoba lagi untuk mengirim data.
• Banyak Producer dapat mengirim data ke Kafka secara bersamaan

Producer dapat ditulis dalam bahasa apa pun, namun Nativenya adalah Java, C/C++, Python, Go, .NET, dan JMS. Banyak juga bahasa yang berasal dari Community, dan Proxy REST untuk Bahasa apa pun yang tidak didukung.

## Broker

![image](https://github.com/user-attachments/assets/5e71c528-c7bf-441e-bd7a-6eaa93d0566a)

Kafka terdiri dari sekelompok yang disebut broker. Secara formal, Kafka adalah sebuah cluster yang terdiri dari banyak broker 

• Broker menerima data dari Producer dan menyimpannya sementara di page cache, atau secara permanen di disk setelah OS membersihkan page cache
• Broker menyimpan data agar siap untuk di-streaming consumer 

• Berapa lama data disimpan ditentukan oleh apa yang disebut **retention time** (1 minggu secara default)

## Consumer

![image](https://github.com/user-attachments/assets/4774bddd-6b79-48d4-9ab1-a1d73fdac833)

Aplikasi yang membaca data ini ke Kafka disebut Consumer.
• Seorang Consumer melakukan polling data dari Kafka
• Setiap Consumer secara berkala bertanya kepada broker klaster Kafka: "Apakah Anda memiliki lebih banyak data untuk saya?". Biasanya konsumen melakukan ini dalam lingkaran tanpa akhir.
• Banyak Consumer dapat melakukan polling data dari Kafka pada saat yang sama
• Banyak Consumer yang berbeda dapat melakukan polling data yang sama, masing-masing dengan kecepatan mereka sendiri
• Untuk memungkinkan paralelisme, Consumer diorganisasikan dalam **consumer group** yang membagi pekerjaan

Pesan masuk baru diambil secara otomatis oleh consumer dengan melacak pesan terakhir yang dibaca (Offset). Offset consumer disimpan dalam topik khusus `__consumer_offsets`.

![image](https://github.com/user-attachments/assets/11369d04-fcd1-41fb-986f-83800f92235b)

Consumer group terdiri dari 1 hingga banyak instans konsumen yang memparalelkan pekerjaan hingga jumlah instans consumer sama dengan jumlah partisi topik. Semua instans consumer dalam consumer group merupakan klon identik satu sama lain. Agar dapat ditambahkan secara transparan ke dalam consumer group, instans perlu menggunakan group.id yang sama. 

## Zookeeper

![image](https://github.com/user-attachments/assets/fbf4cd46-b254-46f2-973c-1304a22d3144)

Broker Kafka menggunakan ZooKeeper untuk sejumlah fitur internal penting seperti

- Manajemen klaster
- Deteksi dan pemulihan kegagalan (misalnya saat broker mati)
- Untuk menyimpan Access Control Lists (ACL) yang digunakan untuk otorisasi di klaster Kafka

## Arsikektur

![image](https://github.com/user-attachments/assets/166c683a-7d89-42f4-a583-1d2d25c752a8)

• Produser di sebelah kiri menulis data ke Kafka
• Di tengah, kluster Kafka yang terdiri dari banyak broker yang menerima dan menyimpan
data
• Di sebelah kanan, consumer yang melakukan polling atau membaca data dari Kafka untuk pemrosesan streaming
• Di atas, ada kluster instans ZooKeeper yang membentuk apa yang disebut ensemble

Fitur utama Kafka adalah Producer dan Consumer dipisahkan, yaitu mereka tidak perlu mengetahui keberadaan satu sama lain, sehingga:
- Konsumen yang lambat tidak memengaruhi Producer
- Consumer yang lambat tidak akan memengaruhi Producer.
- Penambahan Consumer tidak memengaruhi Producer
- Kegagalan Consumer tidak memengaruhi Sistem upstream
- Logika internal Producer tidak pernah bergantung pada downstream consumer 
- Internal konsumen tidak bergantung pada upstream producer
- Producer dan Consumer hanya perlu menyetujui format data record yang diproduksi dan dikonsumsi.

## Topic

![image](https://github.com/user-attachments/assets/1417cb54-4184-4091-9590-148ec80af4df)

Topic adalah aliran pesan yang berhubungan di Kafka. Topic merupakan representasi logika yang mengkategorikan pesan-pesan ke dalam kelompok. Jumlah topic pada broker tidak terbatas.

![image](https://github.com/user-attachments/assets/a65df54d-5eb8-49cc-a55d-3a9acfdf2cf9)

• **Topik:** Topik mencakup semua pesan dari kategori tertentu. Misalnya, kita dapat memiliki topik "temperature_readings" yang akan berisi semua pesan yang berisi pembacaan suhu dari salah satu dari banyak stasiun pengukuran yang dimiliki perusahaan di seluruh dunia. 

• **Partisi**: Untuk memparalelkan pekerjaan dan dengan demikian meningkatkan hasil, Kafka dapat membagi satu topik menjadi banyak partisi. Pesan-pesan dari topik tersebut kemudian akan dibagi di antara partisi-partisi tersebut. Algoritme default yang digunakan untuk memutuskan ke partisi mana pesan akan dikirim menggunakan kode hash dari kunci pesan. Partisi ditangani secara keseluruhan oleh satu broker Kafka. Partisi dapat dilihat sebagai "log".

• **Segmen**: Broker menyimpan pesan saat masuk ke memori (cache halaman), kemudian secara berkala membuangnya ke file fisik. Karena datanya berpotensi tidak terbatas, broker menggunakan strategi "rolling-file". Ia membuat/mengalokasikan berkas baru dan mengisinya dengan
pesan. Ketika segmen penuh (atau waktu maksimum yang diberikan per segmen berakhir), yang berikutnya dialokasikan oleh broker. Kafka menggulirkan berkas dalam segmen untuk memudahkan mengelola retensi data dan menghapus data lama

## Log

![image](https://github.com/user-attachments/assets/99ce7421-4b55-4fd6-8dcb-a9b5fa403a12)

Log adalah struktur data yang seperti antrean elemen. Elemen baru selalu ditambahkan di akhir log dan setelah ditulis, elemen tersebut tidak pernah diubah. Dalam hal ini, seseorang berbicara tentang struktur data yang hanya ditambahkan dan ditulis sekali. Elemen yang ditambahkan ke log diurutkan secara ketat berdasarkan waktu. Elemen pertama yang ditambahkan ke log lebih lama daripada elemen kedua yang pada gilirannya lebih lama daripada elemen ketiga.

## Element Data

![image](https://github.com/user-attachments/assets/b157e87a-b898-46c0-827c-06389ea76d82)

Elemen data dalam log disebut **record** dalam dunia Kafka, bisa juga **message** atau **event**. Record dalam Kafka terdiri dari **Metadata** dan **Body**. 
• Metadata berisi offset, kompresi, magic byte, timestamp, dan kumpulan header opsional dari 0 hingga banyak pasangan key value. 
• Body terdiri dari bagian Key dan Value
• Bagian value biasanya berisi data bisnis yang relevan 
• Key secara default digunakan untuk memutuskan partisi mana rekaman ditulis. Akibatnya, semua rekaman dengan kunci yang identik masuk ke partisi yang sama. 
• Pada timestamp, creation time merupakan waktu dimana message dibuat, sedangkan ingestion time adalah waktu dimana message diterima oleh broker.

Default Strategi Partitioning: 
`hash(key) % number_of_partitions`

No Key → `Round-Robin`

## Replication

![image](https://github.com/user-attachments/assets/547bfc85-8094-492c-b342-4bafd237071e)

Kafka dapat mereplikasi partisi di sejumlah server Kafka yang dapat dikonfigurasi yang digunakan untuk toleransi kesalahan. Setiap partisi memiliki server pemimpin dan nol atau lebih server pengikut. Pemimpin menangani semua permintaan baca dan tulis untuk partisi. Dalam gambar ini, kita memiliki empat broker dan tiga partisi yang direplikasi. Faktor replikasi juga 3. Untuk setiap partisi, broker yang berbeda adalah pemimpin, untuk penggunaan sumber daya yang optimal.

## Producer di Java

![image](https://github.com/user-attachments/assets/54e2ef3f-c83e-45e4-b50e-acc2d2170efd)

Saat menulis Producer dasar di Java, kita dapat membedakan empat bagian:

• Konfigurasi: ini adalah bagian tempat kita mendefinisikan semua properti non-default dari producer kita
• Konstruktor: Di sini kita membangun objek produser menggunakan nilai konfigurasi
• Shutdown: Di bagian ini kita mendefinisikan bagaimana aplikasi akan berperilaku jika menerima sinyal `SIG_TERM` atau `SIG_KILL`
• Sending: Di bagian ini kita mendefinisikan logika yang benar-benar mengirim pesan ke topik terkait di kluster Kafka

![image](https://github.com/user-attachments/assets/3f982a9f-1734-4fd8-a4b3-44fcd44c0394)


## Consumer di .NET/C#

![image](https://github.com/user-attachments/assets/c88e0b1d-cad3-4e1a-ae8e-6c5624b111c1)

Saat menulis consumer dasar (di sini dalam C#, .NET) kita dapat membedakan bagian-bagian berikut:

• Konfigurasi: Di ​​bagian ini kita mendefinisikan nilai non-default dari berbagai parameter konfigurasi yang digunakan saat membuat objek konsumen.
• Message Callback: Dalam callback ini, yang dipicu untuk setiap pesan, kita mendefinisikan apa yang akan terjadi dengan pesan tertentu.
• Error Callbacks: Setiap kali terjadi kesalahan selama penanganan pesan atau kesalahan tak terduga, salah satu metode panggilan balik ini dipanggil. Di sini kita hanya melaporkan pengecualian tersebut ke `STDOUT`
• Subscription: Di sini konsumen berlangganan ke topik yang diinginkan
• Polling: Di sini kita mendefinisikan bagaimana consumer akan melakukan polling. Dalam contoh ini dalam loop tak berujung dengan waktu tunggu 100 ms di antara polling

## Delivery

![image](https://github.com/user-attachments/assets/8fec0296-d718-4012-8cbb-1fe810b8b310)

Pengaturan konfigurasi acks adalah jumlah pengakuan-tulis yang diterima yang diperlukan dari pemimpin partisi sebelum permintaan tulis producer dianggap selesai. Pengaturan ini mengontrol ketahanan producer yang bisa sangat kuat (all) atau tidak sama sekali (none). 

Ketahanan adalah tradeoff antara throughput dan konsistensi. 

• **Acks 0 (NONE):** Producer tidak menunggu ack apa pun dari broker Kafka sama sekali. Rekaman yang ditambahkan ke buffer soket dianggap terkirim. Tidak ada jaminan ketahanan. Offset rekaman yang dikembalikan dari metode kirim diatur ke -1
(unknown). Mungkin ada kehilangan rekaman jika pemimpin mati. Mungkin ada kasus penggunaan yang perlu memaksimalkan throughput daripada daya tahan, misalnya, agregasi log. 

• **Acks 1 (LEADER):** Pengakuan pemimpin. Ini berarti bahwa broker Kafka mengakui bahwa pemimpin partisi menulis rekaman ke log lokalnya tetapi merespons tanpa pengikut partisi mengonfirmasikan penulisan. Jika pemimpin gagal tepat setelah mengirim ack, rekaman dapat hilang karena pengikut mungkin belum mereplikasi rekaman. Kehilangan rekaman jarang terjadi tetapi mungkin, dan mungkin hanya melihat ini digunakan jika rekaman yang jarang terlewatkan tidak signifikan secara statistik, agregasi log, kumpulan data untuk pembelajaran mesin atau dasbor, dll. 

• **Acks -1 (ALL):** semua pengakuan yang berarti pemimpin mendapat konfirmasi penulisan dari set lengkap ISR sebelum mengirim ack kembali ke produsen. Ini menjamin bahwa rekaman tidak hilang selama satu ISR tetap aktif. Pengaturan ack=all ini adalah jaminan terkuat yang tersedia yang diberikan Kafka untuk ketahanan. Pengaturan ini bahkan lebih kuat dengan pengaturan broker min.insync.replicas yang menentukan jumlah minimum ISR yang harus mengakui penulisan. Sebagian besar kasus penggunaan akan menggunakan acks=all dan menetapkan min.insync.replicas > 1.

![image](https://github.com/user-attachments/assets/8d22be3c-d4e4-45eb-9265-a15830988f0f)

Kafka mendukung 3 jaminan pengiriman:

• **At most once:** Dari semua catatan yang ditulis ke Kafka, dijamin tidak akan pernah ada duplikat. Dalam keadaan buruk tertentu, beberapa catatan mungkin hilang

• **At least once:** Dari semua catatan yang ditulis ke Kafka, tidak ada yang pernah hilang. Dalam situasi buruk tertentu, mungkin ada duplikat dalam log

• **Exactly once:** Setiap catatan yang ditulis ke Kafka akan ditemukan dalam log Kafka tepat satu kali. Tidak ada situasi di mana catatan hilang atau di mana catatan diduplikasi. Untuk mencapai Exactly-Once-Semantics (EOS), langkah pertama adalah menetapkan produsen idempoten. Hal ini berguna untuk jaminan transaksional yang kuat untuk, mencegah klien memproses pesan duplikat, dan menangani kegagalan dengan baik. Kasus Penggunaan berupa melacak tampilan iklan dan memproses transaksi keuangan



