# Membangun Event Streaming Pipeline
## Aplikasi Apache Kafka Streams

Kafka Streams adalah library klien Java untuk membangun aplikasi dan layanan mikro, di mana data input dan output disimpan dalam cluster Kafka.

![image](https://github.com/user-attachments/assets/ec22f394-b72d-4c82-8f0b-f0ff25a05f8d)

Sebuah stream mencakup seluruh masa lalu, masa kini, dan masa depan.

Dalam gambar di atas, kita melihat aliran event tersebut di sisi kiri. Setiap event merupakan debit atau kredit ke rekening bank. Seseorang bisa melihat seluruh riwayat dari stream, namun, jika hanya ingin melihat status saldo pada waktu tertentu, bisa gunakan table.

![image](https://github.com/user-attachments/assets/fa0c38c3-af75-4bcf-9de2-8c96a2f81dfb)

• Source Processor: Sebuah source processor adalah jenis khusus dari stream processor yang tidak memiliki prosesor hulu. Ia menghasilkan aliran input ke topologinya dari satu atau beberapa topik Kafka dengan menggunakan rekaman dari topik-topik ini dan meneruskannya ke prosesor hilirnya. 

• Sink Processor: Sebuah sink processor adalah jenis khusus dari stream processor yang tidak memiliki prosesor hilir. Ia mengirimkan record yang diterima dari prosesor hulunya ke topik Kafka tertentu.

![image](https://github.com/user-attachments/assets/a5287bf4-ebbe-4de4-acde-99558e3b2390)

Diagram ini menunjukkan aplikasi Kafka Streams yang memiliki beberapa thread stream, masing-masing dengan beberapa tugas. Thread dapat berjalan paralel di satu sistem atau didistribusikan untuk skalabilitas. Setiap thread memiliki konsumen dan produsen, serta tugas yang menyimpan status lokal di RocksDB, yang dipersistenkan ke topik changelog Kafka.

Windows:
- Membagi stream menjadi "time bucket"
- Tumbling, Hopping, dan Session Windows

![image](https://github.com/user-attachments/assets/2e174f1f-b447-4cf9-bdc9-1349b6e7fd2a)

Aggregations:
- Mengakumulasi sejumlah value saat rekaman baru masuk
- Biasanya berjendela
- Contoh: sum, count, max, min

Joins:
- Gabungkan stream/tabel yang berbeda bersama-sama pada sebuah kunci
- Contoh: Gabungkan aliran lokasi pengemudi dengan tabel profil pengemudi pada kunci ID pengemudi untuk membuat stream yang diperkaya dengan info lokasi dan profil
- Dapat dijendela dengan "sliding window"

### Contoh Kafka Streams (Konfigurasi)

```
public class SimpleStreamsExample {
   public static void main(String[] args) throws Exception {
      Properties config = new Properties();
      // Give the Streams application a unique name. The name must be unique in the Kafka cluster
      config.put(StreamsConfig.APPLICATION_ID_CONFIG, "simple-streams-example");
      config.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, "broker-1:9092,broker-2:9092");
      config.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest");
      // Specify default (de)serializers for record keys and for record values.
      config.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.ByteArray().getClass());
      config.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass());
  }
}
```

- Baris 8 menunjukkan konfigurasi khusus untuk consumer aplikasi Kafka Streams. Ini memungkinkan untuk melakukan hal-hal seperti menyetel pengaturan batch produser di aplikasi Kafka Streams.
- Baris 10 dan 12 menunjukkan kunci dan nilai SerDes. Dalam contoh ini, tipe data akan sama untuk pesan masuk dan keluar sehingga SerDes tidak perlu ditimpa oleh kode.

### Contoh Kafka Streams (Topology)

```
     StreamsBuilder builder = new StreamsBuilder();
  
     // Construct a KStream from the input Topic "TextLinesTopic"
     KStream<byte[], String> textLines = builder.stream("TextLinesTopic");
     // Convert to upper case
     KStream<byte[], String> uppercasedWithMapValues =
     textLines.mapValues(value -> value.toUpperCase());
     // Write the results to a new Kafka Topic called "UppercasedTextLinesTopic".
     uppercasedWithMapValues.to("UppercasedTextLinesTopic");
     // Run the Streams application via `start()`
     streams.start();
     KafkaStreams streams = new KafkaStreams(builder.build(), config);
     // Stop the application gracefully
     Runtime.getRuntime().addShutdownHook(new Thread(streams::close));
  }
}
```

Objek KStream textLines dibuat dengan menggunakan topik TextLinesTopic. textLines diubah oleh mapValues ​​untuk mengubah semua karakter dalam pesan menjadi huruf kapital, sehingga menghasilkan objek KStream yang disebut uppercasedWithMapValues. KStream yang dihasilkan kemudian diproduksi ke topik UppercasedTextLinesTopic.

## Kafka Connect

![image](https://github.com/user-attachments/assets/5e442ef0-218f-4b5e-9f76-177faff8c676)

Kafka Connect adalah kerangka kerja untuk streaming data antara Apache Kafka dan sistem data lainnya. 

• Conncector: pekerjaan logis yang menyalin data antara Kafka dan sistem lain

• Source Connector: membaca data dari sistem data eksternal ke Kafka 

> Secara internal, konektor sumber menggunakan Kafka Producer
  
• Sink Connector: menulis data Kafka ke sistem data eksternal

> Secara internal, konektor sink menggunakan Kafka Consumer Group
  
