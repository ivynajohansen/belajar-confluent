# Install Confluent Platform

![image](https://github.com/user-attachments/assets/d1124703-f1c5-4e99-a056-b4e954d440ff)

Gambar ini menggambarkan komponen-komponen Confluent Platform, yang dapat diinstal di satu atau beberapa mesin. Dalam pengembangan, semua komponen sering dijalankan di satu mesin, sedangkan dalam produksi, tiap komponen biasanya berjalan di klusternya masing-masing.

Menginstal Confluent Platform melalui arsip TAR membuat pengaturan di environment pengembangan lokal menjadi lebih cepat, sedangkan manajer paket seperti _apt_ dan _yum_ adalah cara paling andal untuk menginstal server kelas produksi dengan memudahkan update dan secara otomatis menangani banyak konfigurasi sistem, seperti pengaturan layanan systemd dan peningkatan batas file handle yang terbuka.

## Install via Tarball

Untuk menginstall Confluent Platform dengan instalasi tarball, buka lab environment dan jalankan command berikut:

```
sudo apt-get install openjdk-11-jre-headless
```

Download dan extract archive TAR Confluent Platform 7.1.1:

```
curl -O http://packages.confluent.io/archive/7.1/confluent-7.1.1.tar.gz
tar xzf confluent-7.1.1.tar.gz
```

![image](https://github.com/user-attachments/assets/81b684ad-074d-46e3-9f9d-708ab8b3b065)

### Konfigurasi CLI Confluent

Set variabel CONFLUENT_HOME ke lokasi instalasi dan tambahkan ke .bashrc.

```
export CONFLUENT_HOME=${HOME}/confluent-7.1.1 \
    && echo "export CONFLUENT_HOME=$CONFLUENT_HOME" >> ~/.bashrc
```

Tambahkan binary Confluent Platform (yang mencakup Confluent CLI) ke variabel PATH.

```
echo "export PATH=$CONFLUENT_HOME/bin:${PATH}" >> ~/.bashrc
```

Aktifkan Bash completion untuk CLI yang menyatu dan sumberkan .bashrc agar semua perubahan berlaku:

```
~/confluent-7.1.1/bin/confluent completion bash | sudo tee /etc/bash_completion.d/confluent \
    && echo "source /etc/bash_completion.d/confluent" >> ~/.bashrc \
    && source ~/.bashrc
```

Sekarang CLI konfluen tersedia di PATH dan memiliki pelengkapan otomatis Tab. 

## Install via Package Manager

Saat menginstal Confluent Platform dengan manajer paket, instalasi tersebut memuat file unit ke dalam systemd, yang berarti manajemen siklus hidup setiap service bisa dibantu dengan systemctl.

Jalankan command berikut untuk menginstal java 11:

```
sudo apt-get install openjdk-11-jre-headless
```

Tambahkan kunci repositori apt Confluent ke kunci apt sistem:

```
wget -qO - https://packages.confluent.io/deb/7.1/archive.key | sudo apt-key add -
```

Tambahkan repositori apt Confluent ke sumber sistem, dan perbarui file indeks paket:

```
sudo add-apt-repository \
    "deb [arch=amd64] https://packages.confluent.io/deb/7.1 stable main" && \
    sudo apt-get update
```

Instal Confluent Platform, termasuk fitur keamanan Confluent Server:

```
sudo apt-get install -y \
    confluent-platform \
    confluent-security
```

Instal Confluent Platform, termasuk fitur keamanan Confluent Server yang ditingkatkan:

```
sudo apt-get install -y \
    confluent-platform \
    confluent-security
```

Jalankan service confluent platform menggunakan systemctl:

```
sudo systemctl start \
    confluent-server
    confluent-zookeeper \
    confluent-kafka-connect \
    confluent-ksqldb \
    confluent-kafka-rest
```

![image](https://github.com/user-attachments/assets/5d0aa3ab-9f5c-4396-8677-b9ee92265480)

## Produce dan Consume Avro Data

Jalankan Service Confluent Platform:

```
confluent local services start
```

![image](https://github.com/user-attachments/assets/ac87e0bb-b031-4df7-9c6f-d5f2bd5928df)

Buat file avro bernama temperature_reading untuk menyimpan nama kota dan value temperature dalam Fahrenheit.

```
cat <<EOF > ~/temperature_reading.avsc
{
 "namespace": "io.confluent.examples",
 "type": "record",
 "name": "temperature_reading",
 "fields": [
    {"name": "city", "type": "string"},
    {"name": "temp", "type": "int", "doc": "temperature in Fahrenheit"} ]
}
EOF
```

Buka 2 terminal. Pada salah satu terminal tersebut, jalankan consumer untuk consume topic bawaan dari lab environment, yaitu `temperatures`. Gunakan String Deserializer untuk membaca avro yang telah dibuat sebelumnya:

```
confluent local services \
    kafka consume temperatures \
    --property print.key=true \
    --property key.deserializer=org.apache.kafka.common.serialization.StringDeserializer \
    --value-format avro
```

Pada terminal yang satu lagi, jalankan producer. Gunakan 'koma' sebagai separator field dan String Serializer untuk mengirim message supaya mengikuti schema avro sebelumnya:

```
confluent local services \
    kafka produce temperatures \
    --property parse.key=true --property key.separator=, \
    --property key.serializer=org.apache.kafka.common.serialization.StringSerializer \
    --value-format avro \
    --property value.schema.file=$HOME/temperature_reading.avsc
```

Masukkan beberapa line message untuk topik:

```
alameda,{"city":"alameda","temp":58}
ashland,{"city":"ashland","temp":62}
nairobi,{"city":"nairobi","temp":65}
sydney,{"city":"sydney","temp":75}
```

![image](https://github.com/user-attachments/assets/64225cf2-51b0-4a9c-aa9e-fb59c6e7f608)

Tampilan terminal Consumer setelah mengambil data yang diproduce:

![image](https://github.com/user-attachments/assets/d10f8ba3-ba03-4014-ab0b-9877266cabe8)

Jika memproduce message yang tidak, sesuai schema, akan muncul error:

```
sydney,{"city":"sydney","temp":"75"}
```

![image](https://github.com/user-attachments/assets/5dc6c99a-f7f0-4a17-b374-4699dc4d110d)

## Run-class Scripts dan Environment Variables

Jalankan command berikut:

```
code $(which kafka-server-start)
```

Perhatikan kode berikut. Environment Variable apa yang diekspor ke proses kafka-run-class dan apa fungsinya?

```
#!/bin/bash
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

if [ $# -lt 1 ];
then
	echo "USAGE: $0 [-daemon] server.properties [--override property=value]*"
	exit 1
fi
base_dir=$(dirname $0)

if [ "x$KAFKA_LOG4J_OPTS" = "x" ]; then
  LOG4J_CONFIG_NORMAL_INSTALL="/etc/kafka/log4j.properties"
  LOG4J_CONFIG_ZIP_INSTALL="$base_dir/../etc/kafka/log4j.properties"
  if [ -e "$LOG4J_CONFIG_NORMAL_INSTALL" ]; then # Normal install layout
    KAFKA_LOG4J_OPTS="-Dlog4j.configuration=file:${LOG4J_CONFIG_NORMAL_INSTALL}"
  elif [ -e "${LOG4J_CONFIG_ZIP_INSTALL}" ]; then # Simple zip file layout
    KAFKA_LOG4J_OPTS="-Dlog4j.configuration=file:${LOG4J_CONFIG_ZIP_INSTALL}"
  else # Fallback to normal default
    KAFKA_LOG4J_OPTS="-Dlog4j.configuration=file:$base_dir/../config/log4j.properties"
  fi
fi
export KAFKA_LOG4J_OPTS

if [ "x$KAFKA_HEAP_OPTS" = "x" ]; then
    export KAFKA_HEAP_OPTS="-Xmx1G -Xms1G"
fi

EXTRA_ARGS=${EXTRA_ARGS-'-name kafkaServer -loggc'}

COMMAND=$1
case $COMMAND in
  -daemon)
    EXTRA_ARGS="-daemon "$EXTRA_ARGS
    shift
    ;;
  *)
    ;;
esac

exec $base_dir/kafka-run-class $EXTRA_ARGS kafka.Kafka "$@"
```

KAFKA_LOG4J_OPTS diekspor dengan nilai default.

```
"-Dlog4j.configuration=file:/etc/kafka/log4j.properties"
```

- Variabel ini digunakan untuk memuat berkas konfigurasi dari /etc/kafka/log4j.properties ke dalam Java Virtual Machine untuk mengonfigurasi pengaturan pencatatan log4j.

- Variabel KAFKA_HEAP_OPTS diekspor dengan nilai default "-Xmx1G -Xms1G", yang akan menetapkan 1 Gigabyte memori ke tumpukan JVM broker Kafka.

Berikut adalah beberapa variable environment yang penting:

- CLASSPATH: Variabel ini penting untuk memuat kelas Java ke dalam Java Virtual Machine (JVM) dari file .jar yang diinstal oleh manajer paket. Secara default, CLASSPATH dibuat dari berbagai direktori di bawah `/usr/share/java/`. Mengetahui hal ini dapat membantu saat men-debug kesalahan saat kelas tidak dimuat karena suatu alasan. Di sisi klien Kafka, CLASSPATH umumnya dimodifikasi untuk menginstrumentasikan aplikasi klien dengan interseptor pemantauan untuk mengirim metrik klien ke Confluent Control Center. Interseptor pemantauan Confluent terletak di `/usr/share/java/monitoring-interceptors/monitoring-interceptors-6.0.0.jar`.

- KAFKA_HEAP_OPTS: Broker Kafka menggunakan heap java untuk mereplikasi partisi dengan sekitar 1 Megabyte per replika. Ukuran heap JVM default untuk broker adalah 1 Gigabyte, yang sering kali terlalu kecil untuk penyebaran produksi besar. Biasanya 4-6 GB direkomendasikan, dengan penyebaran yang sangat besar sebesar 12 GB.

Contoh: `KAFKA_HEAP_OPTS="-Xms6g -Xmx6g"`

- KAFKA_JVM_PERFORMANCE_OPTS: Digunakan untuk menyetel pengumpulan sampah dan konfigurasi JVM lainnya. Berikut adalah contoh penggunaan rekomendasi produksi Confluent:

```
KAFKA_JVM_PERFORMANCE_OPTS="-XX:MetaspaceSize=96m -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:G1HeapRegionSize=16M -XX:MinMetaspaceFreeRatio=50 -XX:MaxMetaspaceFreeRatio=80"
```

- JMX_PORT: Jika port JMX (Java Management Extensions) tidak ditentukan, maka broker Kafka tidak akan mengekspos metriknya melalui JMX.

Contoh: `JMX_PORT=9990`

- JMX_OPTS: Dalam produksi, merupakan hal yang umum untuk menyesuaikan opsi JMX guna mengamankan koneksi dengan SSL. Berikut adalah contoh di mana klien JMX dan broker Kafka harus saling mengautentikasi melalui SSL:

```
KAFKA_JMX_OPTS="-Dcom.sun.management.jmxremote \ -Djavax.net.ssl.keyStore=</path/to/file>.keystore \ -Djavax.net.ssl.keyStorePassword=<keystore-password> \ -Dcom.sun.management.jmxremote.ssl.need.client.auth=true \ -Djavax.net.ssl.trustStore=</path/to/file>.truststore \ -Djavax.net.ssl.trustStorePassword=<truststore-password> \ -Dcom.sun.management.jmxremote.registry.ssl=true"
```

- KAFKA_OPTS: Gunakan variabel ini untuk menyetel opsi JVM lainnya. Variabel ini dapat digunakan untuk memuat file .jaas untuk autentikasi antara Kafka dan ZooKeeper. Misalnya:

`KAFKA_OPTS="-Djava.security.auth.login.config=/path/to/my/zookeeper-client.jaas"`

- LOG_DIR: Gunakan variabel ini untuk menentukan direktori tempat log server ditulis. Variabel ini berguna untuk mengetahui kapan Anda ingin mengurai log server dengan alat selain journalctl. File unit systemd memiliki contoh seperti:

`LOG_DIR=/var/log/kafka`

`LOG_DIR=/var/log/confluent/schema-registry`

- KAFKA_DEBUG: Gunakan variabel ini untuk mengaktifkan debugging jarak jauh. Variabel ini tidak sering digunakan, tetapi mungkin berguna. 5005 adalah port default yang dibuka untuk debugging jarak jauh. Variabel tersebut hanya perlu tidak kosong agar dapat diaktifkan, seperti KAFKA_DEBUG=true.
