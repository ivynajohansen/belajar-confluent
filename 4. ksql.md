# Pengenalan KSQL

KSQL adalah engine SQL streaming untuk Apache Kafka yang menyediakan interface SQL yang sederhana dan interaktif untuk pemrosesan aliran pada topik Kafka. KSQL dapat digunakan untuk menulis query SQL untuk filter, transform, aggregate, dan join data streaming secara real-time, sehingga memudahkan pembuatan aplikasi pemrosesan streaming tanpa menulis kode.

## 1. Start KSQL Server

```
ksql-server-start /home/kafka/confluent/etc/ksqldb/ksql-server.properties
```

## 2. CLI KSQL

Untuk masuk ke CLI KSQL, gunakan command `ksql`

![image](https://github.com/ivynajohansen/belajar-confluent/assets/83331802/c71f313e-b106-4d13-973a-640dc1aa2850)


## 3. Create Stream

Buat stream untuk topic Kafka yang telah dibuat sebelumnya, yaitu `notifications-new`. Topik Kafka bernama 'notifications-new' dengan nama pengguna (username) sebagai Key dan message sebagai Valuenya.

```
CREATE STREAM notifications_new_stream (USERNAME VARCHAR KEY, MESSAGE VARCHAR)
WITH (KAFKA_TOPIC='notifications-new', VALUE_FORMAT='DELIMITED');
```

## 4. Select data dari stream

Untuk select semua data, gunakan:

```
SELECT * FROM notifications_new_stream;
```

![image](https://github.com/ivynajohansen/belajar-confluent/assets/83331802/81ce049f-b6bf-48e1-b39a-bbf1ead197fd)

Untuk select semua data dimana username adalah 'taylor_shift':

```
SELECT * FROM notifications_new_stream \
WHERE username='taylor_shift';
```

![image](https://github.com/ivynajohansen/belajar-confluent/assets/83331802/3e5609c5-78b0-42fd-b4f0-3fb417cc46e9)

# Persistent dan Transient

## Persistent

Query Persistent di ksqlDB terus memproses kejadian masuk dari topik Kafka dan menulis hasilnya ke topik Kafka baru. Jenis kueri ini tahan lama dan tetap ada meskipun server ksqlDB dimulai ulang. Untuk membuat Query Persistent, gunakan `CREATE STREAM` atau `CREATE TABLE`.

Contoh Persistent Query adalah stream yang telah dibuat di atas, atau:

```
CREATE STREAM filtered_click_events AS
  SELECT *
  FROM click_events
  WHERE page = 'home';
```

## Transient

Query Trascient di ksqlDB adalah query one-time yang memproses event dari topik Kafka dan memberikan hasilnya tanpa mempertahankan keluaran ke topik Kafka baru. Jenis kueri ini berguna untuk analisis atau debugging. Contoh Query Transient:

```
SELECT page, COUNT(*)
FROM click_events
GROUP BY page;
```

### Membuat Transient Query di Java

Untuk membuat query Transient diatas yang mengambil semua data dari notifications_new_stream, gunakan code berikut:

```
import java.net.URI;
import java.net.http.HttpClient;
import java.net.http.HttpRequest;
import java.net.http.HttpResponse;
import java.nio.charset.StandardCharsets;

public class Transient {
    public static void main(String[] args) {
        // ksqlDB server URL
        String ksqlDBServerUrl = "http://worker2.k8s.alldataint.com:8088/query";
        
        // ksqlDB query
        String ksqlQuery = "SELECT * FROM notifications_new_stream;";
        
        // Create HTTP client
        HttpClient client = HttpClient.newHttpClient();
        
        // Create the request
        HttpRequest request = HttpRequest.newBuilder()
            .uri(URI.create(ksqlDBServerUrl))
            .header("Content-Type", "application/vnd.ksql.v1+json; charset=utf-8")
            .POST(HttpRequest.BodyPublishers.ofString("{\"ksql\": \"" + ksqlQuery + "\", \"streamsProperties\": {}}"))
            .build();
        
        try {
            // Send the request
            HttpResponse<String> response = client.send(request, HttpResponse.BodyHandlers.ofString());
            
            // Print the response
            System.out.println("Response status code: " + response.statusCode());
            System.out.println("Response body: " + response.body());
        } catch (Exception e) {
            e.printStackTrace();
        }
    }
}
```

![image](https://github.com/ivynajohansen/belajar-confluent/assets/83331802/1b582e58-40be-4296-93f8-ff5f61425fc7)

# Join Stream

## 1. Buat Topic Baru

Buat 2 topic baru: 1 untuk `accounts` dan 1 lagi untuk `transactions`.

```
kafka-topics --create --topic accounts --bootstrap-server worker2.k8s.alldataint.com:9092 --partitions 3 --replication-factor 1
kafka-topics --create --topic transactions --bootstrap-server worker2.k8s.alldataint.com:9092 --partitions 3 --replication-factor 1
```

## 2. Buat Dummy Data

Navigasi ke Confluent Control Center (C3) untuk produce data secara lebih mudah, `http://worker2.k8s.alldataint.com:9021/`.

![image](https://github.com/ivynajohansen/belajar-confluent/assets/83331802/0eb15edc-2768-46fb-b4c3-a81805bc526b)

Buat data untuk `accounts` dan `transactions`, dimana 1 account bisa memiliki banyak transaksi (one-to-many).

## 3. Buat Stream

Di ksqlDB bisa membuat Stream dengan Join dua Stream atau Tabel yang ada berdasarkan key yang sama, seperti account_id. Berikut ini contoh cara membuat stream dengan menggabungkan dua stream berdasarkan field account_id:

Pertama, buat stream untuk accounts dan transactions:

```
CREATE STREAM accounts_stream (
    account_id VARCHAR,
    account_name VARCHAR,
    balance DOUBLE
) WITH (
    KAFKA_TOPIC='accounts',
    VALUE_FORMAT='JSON'
);

CREATE STREAM transactions_stream (
    transaction_id VARCHAR,
    account_id VARCHAR,
    amount DOUBLE,
    timestamp VARCHAR
) WITH (
    KAFKA_TOPIC='transactions',
    VALUE_FORMAT='JSON',
    TIMESTAMP='timestamp',
    TIMESTAMP_FORMAT='yyyy-MM-dd''T''HH:mm:ssXXX'
);
```

Setelah itu, buat stream yang menggabungkan keduanya:

```
CREATE STREAM transaction_history_stream AS
SELECT
    a.account_id,
    a.account_name,
    a.balance,
    t.transaction_id,
    t.amount,
    t.timestamp
FROM
    accounts_stream a
JOIN
    transactions_stream t WITHIN 100 DAYS
ON
    a.account_id = t.account_id;
```

Dalam query diatas, accounts_stream digabungkan dengan transactions_stream berdasarkan key account_id. Stream daily_transactions akan menunjukkan data untuk 100 hari ke belakang. `WITHIN` diperlukan supaya data yang diambil lebih relevan dan tidak overload.

Gunakan Query untuk mengambil data dari stream:

```
SELECT * FROM transaction_history_stream;
```

![image](https://github.com/ivynajohansen/belajar-confluent/assets/83331802/403864c7-7070-410e-ae61-6b3a663dc17b)

